<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Model Exploration | Practical Data Science</title>
  <meta name="description" content="The focus of this document is on data science tools and techniques in R, including basic programming knowledge, visualization practices, modeling, and more, along with exercises to practice further. In addition, the demonstrations of most content in Python is available via Jupyter notebooks." />
  <meta name="generator" content="bookdown 0.20.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Model Exploration | Practical Data Science" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m-clark.github.io/data-processing-and-visualization/" />
  <meta property="og:image" content="https://m-clark.github.io/data-processing-and-visualization/img/nineteeneightyR.png" />
  <meta property="og:description" content="The focus of this document is on data science tools and techniques in R, including basic programming knowledge, visualization practices, modeling, and more, along with exercises to practice further. In addition, the demonstrations of most content in Python is available via Jupyter notebooks." />
  <meta name="github-repo" content="m-clark/data-processing-and-visualization/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Model Exploration | Practical Data Science" />
  
  <meta name="twitter:description" content="The focus of this document is on data science tools and techniques in R, including basic programming knowledge, visualization practices, modeling, and more, along with exercises to practice further. In addition, the demonstrations of most content in Python is available via Jupyter notebooks." />
  <meta name="twitter:image" content="https://m-clark.github.io/data-processing-and-visualization/img/nineteeneightyR.png" />



<meta name="date" content="2020-08-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/R.ico" type="image/x-icon" />
<link rel="prev" href="more.html"/>
<link rel="next" href="model_criticism.html"/>
<script src="libs/jquery-3.5.0/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/font-awesome-5.3.1/css/fontawesome-all.min.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.6.1/grViz.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.9/visNetwork.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-8.1.2/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-8.1.2/highcharts.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-3d.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-more.js"></script>
<script src="libs/highcharts-8.1.2/modules/stock.js"></script>
<script src="libs/highcharts-8.1.2/modules/map.js"></script>
<script src="libs/highcharts-8.1.2/modules/annotations.js"></script>
<script src="libs/highcharts-8.1.2/modules/data.js"></script>
<script src="libs/highcharts-8.1.2/modules/drilldown.js"></script>
<script src="libs/highcharts-8.1.2/modules/item-series.js"></script>
<script src="libs/highcharts-8.1.2/modules/offline-exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-8.1.2/modules/exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/export-data.js"></script>
<script src="libs/highcharts-8.1.2/modules/funnel.js"></script>
<script src="libs/highcharts-8.1.2/modules/heatmap.js"></script>
<script src="libs/highcharts-8.1.2/modules/treemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/sankey.js"></script>
<script src="libs/highcharts-8.1.2/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-8.1.2/modules/organization.js"></script>
<script src="libs/highcharts-8.1.2/modules/solid-gauge.js"></script>
<script src="libs/highcharts-8.1.2/modules/streamgraph.js"></script>
<script src="libs/highcharts-8.1.2/modules/sunburst.js"></script>
<script src="libs/highcharts-8.1.2/modules/vector.js"></script>
<script src="libs/highcharts-8.1.2/modules/wordcloud.js"></script>
<script src="libs/highcharts-8.1.2/modules/xrange.js"></script>
<script src="libs/highcharts-8.1.2/modules/tilemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/venn.js"></script>
<script src="libs/highcharts-8.1.2/modules/gantt.js"></script>
<script src="libs/highcharts-8.1.2/modules/timeline.js"></script>
<script src="libs/highcharts-8.1.2/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-8.1.2/modules/bullet.js"></script>
<script src="libs/highcharts-8.1.2/modules/coloraxis.js"></script>
<script src="libs/highcharts-8.1.2/modules/dumbbell.js"></script>
<script src="libs/highcharts-8.1.2/modules/lollipop.js"></script>
<script src="libs/highcharts-8.1.2/modules/series-label.js"></script>
<script src="libs/highcharts-8.1.2/plugins/motion.js"></script>
<script src="libs/highcharts-8.1.2/custom/reset.js"></script>
<script src="libs/highcharts-8.1.2/modules/boost.js"></script>
<script src="libs/highchart-binding-0.8.2/highchart.js"></script>
<script src="libs/sigma-1.2.1/sigma.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.layout.forceAtlas2.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.layout.noverlap.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.renderers.parallelEdges.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.plugins.animate.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.renderers.customShapes.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.plugins.dragNodes.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.renderers.customEdgeShapes.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.plugins.relativeSize.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.renderers.edgeLabels.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.parsers.gexf.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.exporters.svg.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.plugins.neighborhoods.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.plugins.filter.min.js"></script>
<script src="libs/sigma-1.2.1/plugins/sigma.renderers.snapshot.min.js"></script>
<script src="libs/sigmajs-binding-0.1.5/sigmajs.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.15/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/book.css" type="text/css" />
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class='before'><a href="./">Practical Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#intended-audience"><i class="fa fa-check"></i>Intended Audience</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#programming-language"><i class="fa fa-check"></i>Programming Language</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#additional-practice"><i class="fa fa-check"></i>Additional Practice</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#outline"><i class="fa fa-check"></i>Outline</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#part-1-information-processing"><i class="fa fa-check"></i>Part 1: Information Processing</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#part-2-programming-basics"><i class="fa fa-check"></i>Part 2: Programming Basics</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#part-3-modeling"><i class="fa fa-check"></i>Part 3: Modeling</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#part-4-visualization"><i class="fa fa-check"></i>Part 4: Visualization</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#part-5-presentation"><i class="fa fa-check"></i>Part 5: Presentation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#workshops"><i class="fa fa-check"></i>Workshops</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#other"><i class="fa fa-check"></i>Other</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#python-notebooks"><i class="fa fa-check"></i>Python notebooks</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#other-r-packages"><i class="fa fa-check"></i>Other R packages</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#history"><i class="fa fa-check"></i>History</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#current-efforts"><i class="fa fa-check"></i>Current Efforts</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part I: Information Processing</b></span></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html"><i class="fa fa-check"></i>Data Structures</a><ul>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#vectors"><i class="fa fa-check"></i>Vectors</a><ul>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#character-strings"><i class="fa fa-check"></i>Character strings</a></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#factors"><i class="fa fa-check"></i>Factors</a></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#logicals"><i class="fa fa-check"></i>Logicals</a></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#numeric-and-integer"><i class="fa fa-check"></i>Numeric and integer</a></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#dates"><i class="fa fa-check"></i>Dates</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#matrices"><i class="fa fa-check"></i>Matrices</a><ul>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#creating-a-matrix"><i class="fa fa-check"></i>Creating a matrix</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#lists"><i class="fa fa-check"></i>Lists</a></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#data-frames"><i class="fa fa-check"></i>Data Frames</a><ul>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#creating-a-data-frame"><i class="fa fa-check"></i>Creating a data frame</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#data-structure-exercises"><i class="fa fa-check"></i>Data Structure Exercises</a><ul>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#excercise-1"><i class="fa fa-check"></i>Excercise 1</a></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#exercise-2"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#thinking-exercises"><i class="fa fa-check"></i>Thinking Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data_structures.html"><a href="data_structures.html#python-data-structures-notebook"><i class="fa fa-check"></i>Python Data Structures Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html"><i class="fa fa-check"></i>Input/Output</a><ul>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#better-faster-approaches"><i class="fa fa-check"></i>Better &amp; Faster Approaches</a></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#r-specific-data"><i class="fa fa-check"></i>R-specific Data</a><ul>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#r-datasets"><i class="fa fa-check"></i>R Datasets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#other-types-of-data"><i class="fa fa-check"></i>Other Types of Data</a></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#on-the-horizon"><i class="fa fa-check"></i>On the Horizon</a></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#big-data"><i class="fa fa-check"></i>Big Data</a></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#io-exercises"><i class="fa fa-check"></i>I/O Exercises</a><ul>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#exercise-1"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#thinking-exercises-1"><i class="fa fa-check"></i>Thinking Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="io.html"><a href="io.html#python-io-notebook"><i class="fa fa-check"></i>Python I/O Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html"><i class="fa fa-check"></i>Indexing</a><ul>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#slicing-vectors"><i class="fa fa-check"></i>Slicing Vectors</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#slicing-matricesdata.frames"><i class="fa fa-check"></i>Slicing Matrices/data.frames</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#label-based-indexing"><i class="fa fa-check"></i>Label-based Indexing</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#position-based-indexing"><i class="fa fa-check"></i>Position-based Indexing</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#mixed-indexing"><i class="fa fa-check"></i>Mixed Indexing</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#non-contiguous"><i class="fa fa-check"></i>Non-contiguous</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#boolean"><i class="fa fa-check"></i>Boolean</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#listdata.frame-extraction"><i class="fa fa-check"></i>List/data.frame Extraction</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#indexing-exercises"><i class="fa fa-check"></i>Indexing Exercises</a><ul>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#exercise-1-1"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#exercise-2-1"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#exercise-3"><i class="fa fa-check"></i>Exercise 3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="indexing.html"><a href="indexing.html#python-indexing-notebook"><i class="fa fa-check"></i>Python Indexing Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pipes.html"><a href="pipes.html"><i class="fa fa-check"></i>Pipes</a><ul>
<li class="chapter" data-level="" data-path="pipes.html"><a href="pipes.html#using-variables-as-they-are-created"><i class="fa fa-check"></i>Using Variables as They are Created</a></li>
<li class="chapter" data-level="" data-path="pipes.html"><a href="pipes.html#pipes-for-visualization-more-later"><i class="fa fa-check"></i>Pipes for Visualization (more later)</a></li>
<li class="chapter" data-level="" data-path="pipes.html"><a href="pipes.html#the-dot"><i class="fa fa-check"></i>The Dot</a></li>
<li class="chapter" data-level="" data-path="pipes.html"><a href="pipes.html#flexibility"><i class="fa fa-check"></i>Flexibility</a></li>
<li class="chapter" data-level="" data-path="pipes.html"><a href="pipes.html#pipes-summary"><i class="fa fa-check"></i>Pipes Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i>Tidyverse</a><ul>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#what-is-the-tidyverse"><i class="fa fa-check"></i>What is the Tidyverse?</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#what-is-tidy"><i class="fa fa-check"></i>What is Tidy?</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#dplyr"><i class="fa fa-check"></i>dplyr</a><ul>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#an-example"><i class="fa fa-check"></i>An example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#running-example"><i class="fa fa-check"></i>Running Example</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#selecting-columns"><i class="fa fa-check"></i>Selecting Columns</a><ul>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#helper-functions"><i class="fa fa-check"></i>Helper functions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#filtering-rows"><i class="fa fa-check"></i>Filtering Rows</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#generating-new-data"><i class="fa fa-check"></i>Generating New Data</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#grouping-and-summarizing-data"><i class="fa fa-check"></i>Grouping and Summarizing Data</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#renaming-columns"><i class="fa fa-check"></i>Renaming Columns</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#merging-data"><i class="fa fa-check"></i>Merging Data</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#pivoting-axes"><i class="fa fa-check"></i>Pivoting axes</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#more-tidyverse"><i class="fa fa-check"></i>More Tidyverse</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#personal-opinion"><i class="fa fa-check"></i>Personal Opinion</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#tidyverse-exercises"><i class="fa fa-check"></i>Tidyverse Exercises</a><ul>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#exercise-0"><i class="fa fa-check"></i>Exercise 0</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#exercise-1-2"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#exercise-2-2"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#exercise-3-1"><i class="fa fa-check"></i>Exercise 3</a></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#exercise-4"><i class="fa fa-check"></i>Exercise 4</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="tidyverse.html"><a href="tidyverse.html#python-pandas-notebook"><i class="fa fa-check"></i>Python Pandas Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html"><i class="fa fa-check"></i>data.table</a><ul>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#data.table-basics"><i class="fa fa-check"></i>data.table Basics</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#grouped-operations"><i class="fa fa-check"></i>Grouped Operations</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#faster"><i class="fa fa-check"></i>Faster!</a><ul>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#joins"><i class="fa fa-check"></i>Joins</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#group-by"><i class="fa fa-check"></i>Group by</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#string-matching"><i class="fa fa-check"></i>String matching</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#reading-files"><i class="fa fa-check"></i>Reading files</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#more-speed"><i class="fa fa-check"></i>More speed</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#pipe-with-data.table"><i class="fa fa-check"></i>Pipe with data.table</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#data.table-summary"><i class="fa fa-check"></i>data.table Summary</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#faster-dplyr-alternatives"><i class="fa fa-check"></i>Faster dplyr Alternatives</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#data.table-exercises"><i class="fa fa-check"></i>data.table Exercises</a><ul>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#exercise-0-1"><i class="fa fa-check"></i>Exercise 0</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#exercise-1-3"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="data_table.html"><a href="data_table.html#exercise-2-3"><i class="fa fa-check"></i>Exercise 2</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part II: Programming</b></span></li>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html"><i class="fa fa-check"></i>Programming Basics</a><ul>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#r-objects"><i class="fa fa-check"></i>R Objects</a><ul>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#object-inspection-exploration"><i class="fa fa-check"></i>Object Inspection &amp; Exploration</a></li>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#methods"><i class="fa fa-check"></i>Methods</a></li>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#s4-classes"><i class="fa fa-check"></i>S4 classes</a></li>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#others"><i class="fa fa-check"></i>Others</a></li>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#inspecting-functions"><i class="fa fa-check"></i>Inspecting Functions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#help-files"><i class="fa fa-check"></i>Help Files</a></li>
<li class="chapter" data-level="" data-path="programming.html"><a href="programming.html#objects-exercises"><i class="fa fa-check"></i>Objects Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html"><i class="fa fa-check"></i>Iterative Programming</a><ul>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#for-loops"><i class="fa fa-check"></i>For Loops</a><ul>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#a-slight-speed-gain"><i class="fa fa-check"></i>A slight speed gain</a></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#while-alternative"><i class="fa fa-check"></i>While alternative</a></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#loops-summary"><i class="fa fa-check"></i>Loops summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#implicit-loops"><i class="fa fa-check"></i>Implicit Loops</a><ul>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#apply-family"><i class="fa fa-check"></i>apply family</a></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#apply-functions"><i class="fa fa-check"></i>Apply functions</a></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#purrr"><i class="fa fa-check"></i>purrr</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#looping-with-lists"><i class="fa fa-check"></i>Looping with Lists</a></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#iterative-programming-exercises"><i class="fa fa-check"></i>Iterative Programming Exercises</a><ul>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#exercise-1-4"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#exercise-2-4"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="iterative.html"><a href="iterative.html#exercise-3-2"><i class="fa fa-check"></i>Exercise 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i>Writing Functions</a><ul>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#a-starting-point"><i class="fa fa-check"></i>A Starting Point</a></li>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#dry"><i class="fa fa-check"></i>DRY</a></li>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#conditionals"><i class="fa fa-check"></i>Conditionals</a></li>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#anonymous-functions"><i class="fa fa-check"></i>Anonymous functions</a></li>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#writing-functions-exercises"><i class="fa fa-check"></i>Writing Functions Exercises</a><ul>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#excercise-1-1"><i class="fa fa-check"></i>Excercise 1</a></li>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#excercise-1b"><i class="fa fa-check"></i>Excercise 1b</a></li>
<li class="chapter" data-level="" data-path="functions.html"><a href="functions.html#exercise-2-5"><i class="fa fa-check"></i>Exercise 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html"><i class="fa fa-check"></i>More Programming</a><ul>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#code-style"><i class="fa fa-check"></i>Code Style</a><ul>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#why-does-your-code-exist"><i class="fa fa-check"></i>Why does your code exist?</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#assignment"><i class="fa fa-check"></i>Assignment</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#code-length"><i class="fa fa-check"></i>Code length</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#spacing"><i class="fa fa-check"></i>Spacing</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#naming-things"><i class="fa fa-check"></i>Naming things</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#other-1"><i class="fa fa-check"></i>Other</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#vectorization"><i class="fa fa-check"></i>Vectorization</a><ul>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#boolean-indexing"><i class="fa fa-check"></i>Boolean indexing</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#vectorized-operations"><i class="fa fa-check"></i>Vectorized operations</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#regular-expressions"><i class="fa fa-check"></i>Regular Expressions</a><ul>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#typical-uses"><i class="fa fa-check"></i>Typical uses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#code-style-exercises"><i class="fa fa-check"></i>Code Style Exercises</a><ul>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#exercise-1-5"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#exercise-2-6"><i class="fa fa-check"></i>Exercise 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#vectorization-exercises"><i class="fa fa-check"></i>Vectorization Exercises</a><ul>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#exercise-1-6"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#exercise-2-7"><i class="fa fa-check"></i>Exercise 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#regex-exercises"><i class="fa fa-check"></i>Regex Exercises</a><ul>
<li class="chapter" data-level="" data-path="more.html"><a href="more.html#exercise-1-7"><i class="fa fa-check"></i>Exercise 1</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part III: Modeling</b></span></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html"><i class="fa fa-check"></i>Model Exploration</a><ul>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#model-taxonomy"><i class="fa fa-check"></i>Model Taxonomy</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#linear-models"><i class="fa fa-check"></i>Linear models</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#estimation"><i class="fa fa-check"></i>Estimation</a><ul>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#minimizing-and-maximizing"><i class="fa fa-check"></i>Minimizing and maximizing</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#optimization"><i class="fa fa-check"></i>Optimization</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#fitting-models"><i class="fa fa-check"></i>Fitting Models</a><ul>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#using-matrices"><i class="fa fa-check"></i>Using matrices</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#summarizing-models"><i class="fa fa-check"></i>Summarizing Models</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#variable-transformations"><i class="fa fa-check"></i>Variable Transformations</a><ul>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#numeric-variables"><i class="fa fa-check"></i>Numeric variables</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#categorical-variables"><i class="fa fa-check"></i>Categorical variables</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#scales-indices-and-dimension-reduction"><i class="fa fa-check"></i>Scales, indices, and dimension reduction</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#dont-discretize"><i class="fa fa-check"></i>Donâ€™t discretize</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#variable-importance"><i class="fa fa-check"></i>Variable Importance</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#extracting-output"><i class="fa fa-check"></i>Extracting Output</a><ul>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#package-support"><i class="fa fa-check"></i>Package support</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#visualization"><i class="fa fa-check"></i>Visualization</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#extensions-to-the-standard-linear-model"><i class="fa fa-check"></i>Extensions to the Standard Linear Model</a><ul>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#different-types-of-targets"><i class="fa fa-check"></i>Different types of targets</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#correlated-data"><i class="fa fa-check"></i>Correlated data</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#other-extensions"><i class="fa fa-check"></i>Other extensions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#model-exploration-summary"><i class="fa fa-check"></i>Model Exploration Summary</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#model-exploration-exercises"><i class="fa fa-check"></i>Model Exploration Exercises</a><ul>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#exercise-1-8"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#exercise-2-8"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#exercise-3-3"><i class="fa fa-check"></i>Exercise 3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="models.html"><a href="models.html#python-model-exploration-notebook"><i class="fa fa-check"></i>Python Model Exploration Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html"><i class="fa fa-check"></i>Model Criticism</a><ul>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#model-fit"><i class="fa fa-check"></i>Model Fit</a><ul>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#standard-linear-model"><i class="fa fa-check"></i>Standard linear model</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#beyond-ols"><i class="fa fa-check"></i>Beyond OLS</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#classification"><i class="fa fa-check"></i>Classification</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#model-assumptions"><i class="fa fa-check"></i>Model Assumptions</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#predictive-performance"><i class="fa fa-check"></i>Predictive Performance</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#model-comparison"><i class="fa fa-check"></i>Model Comparison</a><ul>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#example-additional-covariates"><i class="fa fa-check"></i>Example: Additional covariates</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#example-interactions"><i class="fa fa-check"></i>Example: Interactions</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#example-additive-models"><i class="fa fa-check"></i>Example: Additive models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#model-averaging"><i class="fa fa-check"></i>Model Averaging</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#model-criticism-summary"><i class="fa fa-check"></i>Model Criticism Summary</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#model-criticism-exercises"><i class="fa fa-check"></i>Model Criticism Exercises</a><ul>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#exercise-0-2"><i class="fa fa-check"></i>Exercise 0</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#exercise-1-9"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#exercise-2-9"><i class="fa fa-check"></i>Exercise 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model_criticism.html"><a href="model_criticism.html#python-model-criticism-notebook"><i class="fa fa-check"></i>Python Model Criticism Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html"><i class="fa fa-check"></i>Machine Learning</a><ul>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#concepts"><i class="fa fa-check"></i>Concepts</a><ul>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#loss"><i class="fa fa-check"></i>Loss</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#bias-variance-tradeoff"><i class="fa fa-check"></i>Bias-variance tradeoff</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#regularization"><i class="fa fa-check"></i>Regularization</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#cross-validation"><i class="fa fa-check"></i>Cross-validation</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#optimization-1"><i class="fa fa-check"></i>Optimization</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#tuning-parameters"><i class="fa fa-check"></i>Tuning parameters</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#techniques"><i class="fa fa-check"></i>Techniques</a><ul>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#regularized-regression"><i class="fa fa-check"></i>Regularized regression</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#random-forests"><i class="fa fa-check"></i>Random forests</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#neural-networks"><i class="fa fa-check"></i>Neural networks</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#interpreting-the-black-box"><i class="fa fa-check"></i>Interpreting the Black Box</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#machine-learning-summary"><i class="fa fa-check"></i>Machine Learning Summary</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#machine-learning-exercises"><i class="fa fa-check"></i>Machine Learning Exercises</a><ul>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#exercise-1-10"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#exercise-2-10"><i class="fa fa-check"></i>Exercise 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ml.html"><a href="ml.html#python-machine-learning-notebook"><i class="fa fa-check"></i>Python Machine Learning Notebook</a></li>
</ul></li>
<li class="part"><span><b>Part IV: Visualization</b></span></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html"><i class="fa fa-check"></i>ggplot2</a><ul>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#layers"><i class="fa fa-check"></i>Layers</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#piping"><i class="fa fa-check"></i>Piping</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#aesthetics"><i class="fa fa-check"></i>Aesthetics</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#geoms"><i class="fa fa-check"></i>Geoms</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#examples"><i class="fa fa-check"></i>Examples</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#stats"><i class="fa fa-check"></i>Stats</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#scales"><i class="fa fa-check"></i>Scales</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#facets"><i class="fa fa-check"></i>Facets</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#multiple-plots"><i class="fa fa-check"></i>Multiple plots</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#fine-control"><i class="fa fa-check"></i>Fine control</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#themes"><i class="fa fa-check"></i>Themes</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#extensions"><i class="fa fa-check"></i>Extensions</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#ggplot2-summary"><i class="fa fa-check"></i>ggplot2 Summary</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#ggplot2-exercises"><i class="fa fa-check"></i>ggplot2 Exercises</a><ul>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#exercise-0-3"><i class="fa fa-check"></i>Exercise 0</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#exercise-1-11"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#exercise-2-11"><i class="fa fa-check"></i>Exercise 2</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ggplot2.html"><a href="ggplot2.html#python-plotnine-notebook"><i class="fa fa-check"></i>Python Plotnine Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html"><i class="fa fa-check"></i>Interactive Visualization</a><ul>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#packages"><i class="fa fa-check"></i>Packages</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#piping-for-visualization"><i class="fa fa-check"></i>Piping for Visualization</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#htmlwidgets"><i class="fa fa-check"></i>htmlwidgets</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#plotly"><i class="fa fa-check"></i>Plotly</a><ul>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#modes"><i class="fa fa-check"></i>Modes</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#ggplotly"><i class="fa fa-check"></i>ggplotly</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#highcharter"><i class="fa fa-check"></i>Highcharter</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#graph-networks"><i class="fa fa-check"></i>Graph networks</a><ul>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#visnetwork"><i class="fa fa-check"></i>visNetwork</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#sigmajs"><i class="fa fa-check"></i>sigmajs</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#plotly-1"><i class="fa fa-check"></i>Plotly</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#leaflet"><i class="fa fa-check"></i>leaflet</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#dt"><i class="fa fa-check"></i>DT</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#shiny"><i class="fa fa-check"></i>Shiny</a><ul>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#dash"><i class="fa fa-check"></i>Dash</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#interactive-and-visual-data-exploration"><i class="fa fa-check"></i>Interactive and Visual Data Exploration</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#interactive-visualization-exercises"><i class="fa fa-check"></i>Interactive Visualization Exercises</a><ul>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#exercise-0-4"><i class="fa fa-check"></i>Exercise 0</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#exercise-1-12"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#exercise-2-12"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#exercise-3-4"><i class="fa fa-check"></i>Exercise 3</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="interactive.html"><a href="interactive.html#python-interactive-visualization-notebook"><i class="fa fa-check"></i>Python Interactive Visualization Notebook</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html"><i class="fa fa-check"></i>Thinking Visually</a><ul>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#information"><i class="fa fa-check"></i>Information</a><ul>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#your-audience-isnt-dumb"><i class="fa fa-check"></i>Your audience isnâ€™t dumb</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#clarity-is-key"><i class="fa fa-check"></i>Clarity is key</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#avoid-clutter"><i class="fa fa-check"></i>Avoid clutter</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#color-isnt-optional"><i class="fa fa-check"></i>Color isnâ€™t optional</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#think-interactively"><i class="fa fa-check"></i>Think interactively</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#color"><i class="fa fa-check"></i>Color</a><ul>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#viridis"><i class="fa fa-check"></i>Viridis</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#scientific-colors"><i class="fa fa-check"></i>Scientific colors</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#rcolorbrewer"><i class="fa fa-check"></i>RColorBrewer</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#contrast"><i class="fa fa-check"></i>Contrast</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#scaling-size"><i class="fa fa-check"></i>Scaling Size</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#transparency"><i class="fa fa-check"></i>Transparency</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#accessibility"><i class="fa fa-check"></i>Accessibility</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#file-types"><i class="fa fa-check"></i>File Types</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#summary-of-thinking-visually"><i class="fa fa-check"></i>Summary of Thinking Visually</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#a-casual-list-of-things-to-avoid"><i class="fa fa-check"></i>A casual list of things to avoid</a><ul>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#pie"><i class="fa fa-check"></i>Pie</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#histograms"><i class="fa fa-check"></i>Histograms</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#using-3d-without-adding-any-communicative-value"><i class="fa fa-check"></i>Using 3D without adding any communicative value</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#using-too-many-colors"><i class="fa fa-check"></i>Using too many colors</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#using-valenced-colors-when-data-isnt-applicable"><i class="fa fa-check"></i>Using valenced colors when data isnâ€™t applicable</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#showing-maps-that-just-display-population"><i class="fa fa-check"></i>Showing maps that just display population</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#biplots"><i class="fa fa-check"></i>Biplots</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#thinking-visually-exercises"><i class="fa fa-check"></i>Thinking Visually Exercises</a><ul>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#exercise-1-13"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#exercise-2-13"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="thinking_vis.html"><a href="thinking_vis.html#thinking-exercises-2"><i class="fa fa-check"></i>Thinking exercises</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Part V: Presentation</b></span></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i>Building Better Data-Driven Products</a><ul>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#rep-analysis"><i class="fa fa-check"></i>Rep* Analysis</a><ul>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#example"><i class="fa fa-check"></i>Example</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#repeatable"><i class="fa fa-check"></i>Repeatable</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#reproducible"><i class="fa fa-check"></i>Reproducible</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#replicable"><i class="fa fa-check"></i>Replicable</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#summary-of-rep-analysis"><i class="fa fa-check"></i>Summary of rep* analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#literate-programming"><i class="fa fa-check"></i>Literate Programming</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#r-markdown"><i class="fa fa-check"></i>R Markdown</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#version-control"><i class="fa fa-check"></i>Version Control</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#dynamic-data-analysis-report-generation"><i class="fa fa-check"></i>Dynamic Data Analysis &amp; Report Generation</a></li>
<li class="chapter" data-level="" data-path="reproducibility.html"><a href="reproducibility.html#using-modern-tools"><i class="fa fa-check"></i>Using Modern Tools</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html"><i class="fa fa-check"></i>Getting Started</a><ul>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#what-is-markdown"><i class="fa fa-check"></i>What is Markdown?</a></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#documents"><i class="fa fa-check"></i>Documents</a><ul>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#standard-html"><i class="fa fa-check"></i>Standard HTML</a></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#r-notebooks"><i class="fa fa-check"></i>R notebooks</a></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#distill"><i class="fa fa-check"></i>Distill</a></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#bookdown"><i class="fa fa-check"></i>Bookdown</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#presentations"><i class="fa fa-check"></i>Presentations</a></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#apps-sites-dashboards"><i class="fa fa-check"></i>Apps, Sites &amp; Dashboards</a></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#templates"><i class="fa fa-check"></i>Templates</a></li>
<li class="chapter" data-level="" data-path="getting_started.html"><a href="getting_started.html#how-to-begin"><i class="fa fa-check"></i>How to Begin</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html"><i class="fa fa-check"></i>Standard Documents</a><ul>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#r-markdown-files"><i class="fa fa-check"></i>R Markdown files</a></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#text"><i class="fa fa-check"></i>Text</a></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#code"><i class="fa fa-check"></i>Code</a><ul>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#chunks"><i class="fa fa-check"></i>Chunks</a></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#in-line"><i class="fa fa-check"></i>In-line</a></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#labels"><i class="fa fa-check"></i>Labels</a></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#running-code"><i class="fa fa-check"></i>Running code</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#multiple-documents"><i class="fa fa-check"></i>Multiple Documents</a><ul>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#knitting-multiple-documents-into-one"><i class="fa fa-check"></i>Knitting multiple documents into one</a></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#parameterized-reports"><i class="fa fa-check"></i>Parameterized reports</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#collaboration"><i class="fa fa-check"></i>Collaboration</a></li>
<li class="chapter" data-level="" data-path="standard_documents.html"><a href="standard_documents.html#using-python-for-documents"><i class="fa fa-check"></i>Using Python for Documents</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html"><i class="fa fa-check"></i>Customization &amp; Configuration</a><ul>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#output-options"><i class="fa fa-check"></i>Output Options</a><ul>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#themes-etc."><i class="fa fa-check"></i>Themes etc.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#yaml"><i class="fa fa-check"></i>YAML</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#html-css"><i class="fa fa-check"></i>HTML &amp; CSS</a><ul>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#html-1"><i class="fa fa-check"></i>HTML</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#css"><i class="fa fa-check"></i>CSS</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#custom-classes"><i class="fa fa-check"></i>Custom classes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#personal-templates"><i class="fa fa-check"></i>Personal Templates</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#the-rabbit-hole-goes-deep"><i class="fa fa-check"></i>The Rabbit Hole Goes Deep</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#r-markdown-exercises"><i class="fa fa-check"></i>R Markdown Exercises</a><ul>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#exercise-1-14"><i class="fa fa-check"></i>Exercise 1</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#exercise-2-14"><i class="fa fa-check"></i>Exercise 2</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#exercise-3-5"><i class="fa fa-check"></i>Exercise 3</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#exercise-4-1"><i class="fa fa-check"></i>Exercise 4</a></li>
<li class="chapter" data-level="" data-path="customization.html"><a href="customization.html#exercise-5"><i class="fa fa-check"></i>Exercise 5</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Wrap-up</b></span></li>
<li class="chapter" data-level="" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#r-markdown-1"><i class="fa fa-check"></i>R Markdown</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#footnotes"><i class="fa fa-check"></i>Footnotes</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#citations-and-references"><i class="fa fa-check"></i>Citations and references</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#multiple-documents-1"><i class="fa fa-check"></i>Multiple documents</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#web-standards"><i class="fa fa-check"></i>Web standards</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li class='after'">
   <a href="https://m-clark.github.io/" aria-label='Author Website Link'>
      <img src="img/mc_logo.png" style="width:25%; padding:0px 0; display:block; margin: 0 auto;" alt="MC logo">
   </a>
</li>
<li class='after'">
   <div style='text-align:center'>
      <a href="https://github.com/m-clark/" aria-label='GitHub Link'>
         <i class="fab fa-github fa-2x" aria-hidden="true"></i>
      </a>
   </div>
</li>
<li class='after'">
   <div style='text-align:center'>
      <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" aria-label="Creative commons CCBYSA link">
         <i class="fab fa-creative-commons fa-lg"></i> 
         <i class="fab fa-creative-commons-by fa-lg"></i> 
         <i class="fab fa-creative-commons-sa fa-lg"></i>
      </a>
   </div>
</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Practical Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-exploration" class="section level1">
<h1>Model Exploration</h1>
<div style="text-align: center">
<i class="fas  fa-chart-line fa-5x " style="color:#990024;"></i>
</div>
<p>The following section shows how to get started with modeling in R generally, with a focus on concepts, tools, and syntax, rather than trying to understand the specifics of a given model. We first dive into model exploration, getting a sense of the basic mechanics behind our modeling tools, and contemplating standard results. Weâ€™ll then shift our attention to understanding the strengths and limitations of our models. Weâ€™ll then change from classical methods to explore machine learning techniques. The goal of these chapters is to provide an overview of concepts and ways to think about modeling.</p>
<div id="model-taxonomy" class="section level2">
<h2>Model Taxonomy</h2>
<p>We can begin with a taxonomy that broadly describes two classes of models:</p>
<ul>
<li><em>Supervised</em></li>
<li><em>Unsupervised</em></li>
<li>Some combination</li>
</ul>
<p>For supervised settings, there is a target or set of target variables which we aim to predict with a set of predictor variables or covariates. This is far and away the most common case, and the one we will focus on here. It is very common in machine learning parlance to further distinguish <em>regression</em> and <em>classification</em> among supervised models, but what they actually mean to distinguish is numeric target variables from categorical ones (itâ€™s all regression).</p>
<p>In the case of unsupervised models, the data itself is the target, and this setting includes techniques such as principal components analysis, factor analysis, cluster analytic approaches, topic modeling, and many others. A key goal for many such methods is <em>dimension reduction</em>, either of the columns or rows. For example, we may have many items of a survey we wish to group together into a few concepts, or cluster thousands of observations into a few simple categories.</p>
<p>We can also broadly describe two primary goals of modeling:</p>
<ul>
<li><em>Prediction</em></li>
<li><em>Explanation</em></li>
</ul>
<p>Different models will provide varying amounts of predictive and explanatory (or inferential) power. In some settings, prediction is almost entirely the goal, with little need to understand the underlying details of the relation of inputs to outputs. For example, in a model that predicts words to suggest when typing, we donâ€™t really need to know nor much care about the details except to be able to improve those suggestions. In scientific studies however, we may be much more interested in the (potentially causal) relations among the variables under study.</p>
<p>While these are sometimes competing goals, it is definitely not the case that they are mutually exclusive. For example, a fully interpretable model, statistically speaking, may have no predictive capability, and so is fairly useless in practical terms. Often, very predictive models offer little understanding. But sometimes we can luck out and have both a highly predictive model as well as one that is highly interpretable.</p>
</div>
<div id="linear-models" class="section level2">
<h2>Linear models</h2>
<p>Most models you see in published reports are <em>linear models</em> of varying kinds, and form the basis on which to build more complex forms. In such models we distinguish a <em>target variable</em> we want to understand from the variables which we will use to understand it. Note that these come with different names depending on the goal of the study, discipline, and other factors<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a>. The following table denotes common nomenclature across many disciplines.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Type
</th>
<th style="text-align:left;">
Names
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;vertical-align: middle !important;" rowspan="8">
Target
</td>
<td style="text-align:left;">
Dependent variable
</td>
</tr>
<tr>
<td style="text-align:left;">
Endogenous
</td>
</tr>
<tr>
<td style="text-align:left;">
Response
</td>
</tr>
<tr>
<td style="text-align:left;">
Outcome
</td>
</tr>
<tr>
<td style="text-align:left;">
Output
</td>
</tr>
<tr>
<td style="text-align:left;">
Y
</td>
</tr>
<tr>
<td style="text-align:left;">
Regressand
</td>
</tr>
<tr>
<td style="text-align:left;">
Left hand side (LHS)
</td>
</tr>
<tr>
<td style="text-align:left;vertical-align: middle !important;" rowspan="8">
Predictor
</td>
<td style="text-align:left;">
Independent variable
</td>
</tr>
<tr>
<td style="text-align:left;">
Exogenous
</td>
</tr>
<tr>
<td style="text-align:left;">
Explanatory Variable
</td>
</tr>
<tr>
<td style="text-align:left;">
Covariate
</td>
</tr>
<tr>
<td style="text-align:left;">
Input
</td>
</tr>
<tr>
<td style="text-align:left;">
X
</td>
</tr>
<tr>
<td style="text-align:left;">
Regressor
</td>
</tr>
<tr>
<td style="text-align:left;">
Right hand side (RHS)
</td>
</tr>
</tbody>
</table>
<p>A typical way to depict a linear regression model is as follows:</p>
<p><span class="math display">\[y = b_0 + b_1\cdot x_1 + b_2\cdot x_2 + ... +  + b_p\cdot x_p + \epsilon\]</span></p>
<p>In the above, <span class="math inline">\(b_0\)</span> is the intercept, and the other <span class="math inline">\(b_*\)</span> are the regression coefficients that represent the relationship of the predictors <span class="math inline">\(x\)</span> to the target variable <span class="math inline">\(y\)</span>. The <span class="math inline">\(\epsilon\)</span> represents the <em>error</em> or <em>residual</em>. We donâ€™t have perfect prediction, and that represents the difference between what we can guess with our predictor relationships to the target and what we actually observe with it.</p>
<p>In R, we specify a linear model as follows. Conveniently enough, we use a function, <code>lm</code>, that stands for linear model. There are various inputs, typically starting with the formula. In the formula, The target variable is first, followed by the predictor variables, separated by a tilde (<code>~</code>). Additional predictor variables are added with a plus sign (<code>+</code>). In this example, <code>y</code> is our target, and the predictors are <code>x</code> and <code>z</code>.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="models.html#cb372-1"></a><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>z)</span></code></pre></div>
<p>We can still use linear models to investigate nonlinear relationships. For example, in the following, we can add a quadratic term or an interaction, yet the model is still linear in the parameters. All of the following are standard linear regression models.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="models.html#cb373-1"></a><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>z <span class="op">+</span><span class="st"> </span>x<span class="op">:</span>z)</span>
<span id="cb373-2"><a href="models.html#cb373-2"></a><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>x_squared)     <span class="co"># a better way: lm(y ~ poly(x, degree = 2))</span></span></code></pre></div>
<p>In the models above, <code>x</code> has a potentially nonlinear relationship with <code>y</code>, either by varying its (linear) relationship depending on values of z (the first case) or itself (the second). In general, the manner in which nonlinear relationships may be explored in linear models is quite flexible.</p>
<p>An example of a <em>nonlinear model</em> would be population growth models, like exponential or logistic growth curves. You can use functions like <span class="func" style="">nls</span> or <span class="func" style="">nlme</span> for such models, but should have a specific theoretical reason to do so, and even then, flexible models such as <a href="https://m-clark.github.io/generalized-additive-models/">GAMs</a> might be better than assuming a functional form.</p>
</div>
<div id="estimation" class="section level2">
<h2>Estimation</h2>
<p>One key thing to understand with predictive models of any kind is how we estimate the parameters of interest, e.g.Â coefficients/weights, variance, and more. To start with, we must have some sort of goal that choosing a particular set of values for the parameters achieves, and then find some way to reach that goal efficiently.</p>
<div id="minimizing-and-maximizing" class="section level3">
<h3>Minimizing and maximizing</h3>
<p>The goal of many estimation approaches is the reduction of <em>loss</em>, conceptually defined as the difference between the model predictions and the observed data, i.e.Â prediction error. In an introductory methods course, many are introduced to <em>ordinary least squares</em> as a means to estimate the coefficients for a linear regression model. In this scenario, we are seeking to come up with estimates of the coefficients that <em>minimize</em> the (squared) difference between the observed target value and the fitted value based on the parameter estimates. The loss in this case is defined as the sum of the squared errors. Formally we can state it as follows.</p>
<p><span class="math display">\[\mathcal{Loss} = \Sigma(y - \hat{y})^2\]</span></p>
<p>We can see how this works more clearly with some simple conceptual code. In what follows, we create a <a href="functions.html#writing-functions">function</a>, allows us to move <a href="iterative.html#for-loops">row by row</a> through the data, calculating both our prediction based on the given model parameters- <span class="math inline">\(\hat{y}\)</span>, and the difference between that and our target variable <span class="math inline">\(y\)</span>. We sum these squared differences to get a total. In practice such a function is called the loss function, cost function, or objective function.</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="models.html#cb374-1"></a>ls_loss &lt;-<span class="st"> </span><span class="cf">function</span>(X, y, beta) {</span>
<span id="cb374-2"><a href="models.html#cb374-2"></a>  </span>
<span id="cb374-3"><a href="models.html#cb374-3"></a>  <span class="co"># initialize the objects</span></span>
<span id="cb374-4"><a href="models.html#cb374-4"></a>  loss  =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">nrow</span>(X))</span>
<span id="cb374-5"><a href="models.html#cb374-5"></a>  y_hat =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">nrow</span>(X))</span>
<span id="cb374-6"><a href="models.html#cb374-6"></a>  </span>
<span id="cb374-7"><a href="models.html#cb374-7"></a>  <span class="co"># for each row, calculate y_hat and square the difference with y</span></span>
<span id="cb374-8"><a href="models.html#cb374-8"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(X)) {</span>
<span id="cb374-9"><a href="models.html#cb374-9"></a>    y_hat[n] =<span class="st"> </span><span class="kw">sum</span>(X[n, ] <span class="op">*</span><span class="st"> </span>beta)</span>
<span id="cb374-10"><a href="models.html#cb374-10"></a>    loss[n]  =<span class="st"> </span>(y[n] <span class="op">-</span><span class="st"> </span>y_hat[n]) <span class="op">^</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb374-11"><a href="models.html#cb374-11"></a>  }</span>
<span id="cb374-12"><a href="models.html#cb374-12"></a>  </span>
<span id="cb374-13"><a href="models.html#cb374-13"></a>  <span class="kw">sum</span>(loss)  </span>
<span id="cb374-14"><a href="models.html#cb374-14"></a>}</span></code></pre></div>
<p>Now we need some data. Letâ€™s construct some data so that we know the true underlying values for the regression coefficients. Feel free to change the sample size <code>N</code> or the coefficient values.</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="models.html#cb375-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)           <span class="co"># for reproducibility</span></span>
<span id="cb375-2"><a href="models.html#cb375-2"></a>N =<span class="st"> </span><span class="dv">100</span></span>
<span id="cb375-3"><a href="models.html#cb375-3"></a>X =<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="kw">rnorm</span>(N))  <span class="co"># a model matrix; first column represents the intercept</span></span>
<span id="cb375-4"><a href="models.html#cb375-4"></a>y =<span class="st"> </span><span class="dv">5</span> <span class="op">*</span><span class="st"> </span>X[, <span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="fl">.5</span> <span class="op">*</span><span class="st"> </span>X[, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(N)  <span class="co"># a target with some noise; truth is y = 5 +.5*x</span></span>
<span id="cb375-5"><a href="models.html#cb375-5"></a></span>
<span id="cb375-6"><a href="models.html#cb375-6"></a>df =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">y =</span> y, <span class="dt">x =</span> X[, <span class="dv">2</span>])</span></code></pre></div>
<p>Now letâ€™s make some guesses for the coefficients, and see what the corresponding sum of the squared errors, i.e.Â the loss, would be.</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="models.html#cb376-1"></a><span class="kw">ls_loss</span>(X, y, <span class="dt">beta =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))    <span class="co"># guess 1</span></span></code></pre></div>
<pre><code>[1] 2467.106</code></pre>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="models.html#cb378-1"></a><span class="kw">ls_loss</span>(X, y, <span class="dt">beta =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))    <span class="co"># guess 2</span></span></code></pre></div>
<pre><code>[1] 1702.547</code></pre>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="models.html#cb380-1"></a><span class="kw">ls_loss</span>(X, y, <span class="dt">beta =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="fl">.25</span>))  <span class="co"># guess 3</span></span></code></pre></div>
<pre><code>[1] 179.2952</code></pre>
<p>We see that in our third guess we reduce the loss quite a bit relative to our first guess. This makes sense because a value of 4 for the intercept and .25 for the coefficient for <code>x</code> are not as relatively far from the true values.</p>
<p>However, we can also see that they are not the best we could have done. In addition, with more data, our estimated coefficients would get closer to true values.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="models.html#cb382-1"></a>model =<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, df)            <span class="co"># fit the model and obtain parameter estimates using OLS</span></span>
<span id="cb382-2"><a href="models.html#cb382-2"></a><span class="kw">coef</span>(model)                      <span class="co"># best guess given the data </span></span></code></pre></div>
<pre><code>(Intercept)           x 
  4.8971969   0.4475284 </code></pre>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="models.html#cb384-1"></a><span class="kw">sum</span>(<span class="kw">residuals</span>(model)<span class="op">^</span><span class="dv">2</span>)          <span class="co"># least squares loss</span></span></code></pre></div>
<pre><code>[1] 92.34413</code></pre>
<p>In some relatively rare cases, a known approach is available and we do not have to search for the best estimates, but simply have to perform the correct steps that will result in them. For example, the following matrix operations will produce the best estimates for linear regression, which also happen to be the maximum likelihood estimates.</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="models.html#cb386-1"></a><span class="kw">solve</span>(<span class="kw">crossprod</span>(X)) <span class="op">%*%</span><span class="st"> </span><span class="kw">crossprod</span>(X, y)  <span class="co"># &#39;normal equations&#39;</span></span></code></pre></div>
<pre><code>          [,1]
[1,] 4.8971969
[2,] 0.4475284</code></pre>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="models.html#cb388-1"></a><span class="kw">coef</span>(model)</span></code></pre></div>
<pre><code>(Intercept)           x 
  4.8971969   0.4475284 </code></pre>
<p>Most of the time we donâ€™t have such luxury, or even if we did, the computations might be too great for the size of our data.</p>
<p>Many statistical modeling techniques use <em>maximum likelihood</em> in some form or fashion, including Bayesian approaches, so you would do well to understand the basics. In this case, instead of minimizing the loss, we use an approach to maximize the probability of the observations of the target variable given the estimates of the parameters of the model (e.g.Â the coefficients in a regression)<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a>.</p>
<p>The following shows how this would look for estimating a single value like a mean for a set of observations from a specific distribution<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>. In this case, the true underlying value that maximizes the likelihood is 5, but we typically donâ€™t know this. We see that as our guesses for the mean would get closer to 5, the likelihood of the observed values increases. Our final guess based on the observed data wonâ€™t be exactly 5, but with enough data and an appropriate model for that data, we should get close.</p>
<p><img src="practical-data-science_files/figure-html/maximum-likelihood-1.svg" width="75%" style="display: block; margin: auto;" /></p>
<p>Again, some simple conceptual code can help us. The next bit of code follows a similar approach to what we had with least squares regression, but the goal is instead to maximize the likelihood of the observed data. In this example, I fix the estimated variance, but in practice weâ€™d need to estimate that parameter as well. As probabilities are typically very small, we work with them on the log scale.</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="models.html#cb390-1"></a>max_like &lt;-<span class="st"> </span><span class="cf">function</span>(X, y, beta, <span class="dt">sigma =</span> <span class="dv">1</span>) {</span>
<span id="cb390-2"><a href="models.html#cb390-2"></a>  </span>
<span id="cb390-3"><a href="models.html#cb390-3"></a>  likelihood =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">nrow</span>(X))</span>
<span id="cb390-4"><a href="models.html#cb390-4"></a>  y_hat =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">nrow</span>(X))</span>
<span id="cb390-5"><a href="models.html#cb390-5"></a>  </span>
<span id="cb390-6"><a href="models.html#cb390-6"></a>  <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(X)) {</span>
<span id="cb390-7"><a href="models.html#cb390-7"></a>    y_hat[n] &lt;-<span class="st"> </span><span class="kw">sum</span>(X[n, ] <span class="op">*</span><span class="st"> </span>beta)</span>
<span id="cb390-8"><a href="models.html#cb390-8"></a>    likelihood[n] =<span class="st"> </span><span class="kw">dnorm</span>(y[n],  <span class="dt">mean =</span> y_hat[n], <span class="dt">sd =</span> sigma, <span class="dt">log =</span> <span class="ot">TRUE</span>)</span>
<span id="cb390-9"><a href="models.html#cb390-9"></a>  }</span>
<span id="cb390-10"><a href="models.html#cb390-10"></a>  </span>
<span id="cb390-11"><a href="models.html#cb390-11"></a>  <span class="kw">sum</span>(likelihood)  </span>
<span id="cb390-12"><a href="models.html#cb390-12"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="models.html#cb391-1"></a><span class="kw">max_like</span>(X, y, <span class="dt">beta =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))    <span class="co"># guess 1</span></span></code></pre></div>
<pre><code>[1] -1327.593</code></pre>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="models.html#cb393-1"></a><span class="kw">max_like</span>(X, y, <span class="dt">beta =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))    <span class="co"># guess 2</span></span></code></pre></div>
<pre><code>[1] -1022.18</code></pre>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="models.html#cb395-1"></a><span class="kw">max_like</span>(X, y, <span class="dt">beta =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="fl">.25</span>))  <span class="co"># guess 3</span></span></code></pre></div>
<pre><code>[1] -300.6741</code></pre>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="models.html#cb397-1"></a><span class="kw">logLik</span>(model)</span></code></pre></div>
<pre><code>&#39;log Lik.&#39; -137.9115 (df=3)</code></pre>
<p>To better understand maximum likelihood, it might help to think of our model from a data generating perspective, rather than in terms of â€˜errorsâ€™. In the standard regression setting, we think of a single observation as follows:</p>
<p><span class="math display">\[\mu = b_0 + b_1*x_1 + ... + b_p*x_p\]</span></p>
<p>Or with matrix notation (consider it shorthand if not familiar):</p>
<p><span class="math display">\[\mu = X\beta\]</span></p>
<p>Now we display how <span class="math inline">\(y\)</span> is generated:</p>
<p><span class="math display">\[y \sim \mathcal{N}(\mathrm{mean} = \mu, \mathrm{sd} = \sigma)\]</span></p>
<p>In words, this means that our target observation <span class="math inline">\(y\)</span> is assumed to be normally distributed with some mean and some standard deviation/variance. The mean <span class="math inline">\(\mu\)</span> is a function, or simply weighted sum, of our covariates <span class="math inline">\(X\)</span>. The unknown parameters we have to estimate are the <span class="math inline">\(\beta\)</span>, i.e.Â weights, and standard deviation <span class="math inline">\(\sigma\)</span> (or variance <span class="math inline">\(\sigma^2\)</span>).</p>
<p>One more note regarding estimation, it is good to distinguish models from estimation procedures. The following shows the more specific to the more general for both models and estimation procedures respectively.</p>
<div style="width:500px; margin:0 auto; font-family:Roboto; ">
<div id="htmlwidget-2a358d522d1f42144f36" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-2a358d522d1f42144f36">{"x":{"diagram":"digraph models {\ngraph [rankdir = LR  bgcolor=transparent]\n\nnode [shape = rectangle style=filled fillcolor=\"#990024BF\" color=gray80 width=.75]\n\nnode [fontcolor=white fontname=Roboto fixedsize=true fontsize=\"10%\"]\nLM; GLM; GLMM; GAMM;\n\nedge [color=gray50 style=filled]\nLM -> GLM; \nGLM -> GLMM; \nGLMM -> GAMM;\n\n// title\nlabelloc=\"t\";\nlabel=\"Models\\n\\n\";\nfontname=Roboto;\nfontcolor=gray50;\nfontsize=\"15%\"\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<div style="width:500px; margin:0 auto; font-family:Roboto; ">
<div id="htmlwidget-ddee11d9a5ad4b380912" style="width:500px;height:250px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-ddee11d9a5ad4b380912">{"x":{"diagram":"digraph models {\ngraph [rankdir = LR  bgcolor=transparent]\n\nnode [shape = rectangle style=filled fillcolor=\"#990024BF\" color=gray80 width=.75]\n\nnode [fontcolor=white fontname=Roboto fixedsize=true fontsize=\"10%\"]\nOLS; WLS; GLS; GEE; GMM;\n\nedge [color=gray50 style=filled]\nOLS -> WLS; \nWLS -> GLS; \nGLS -> GEE;\nGEE -> GMM;\n\n// title\nlabelloc=\"t\";\nlabel=\"Estimation Procedures\\n\\n\";\nfontname=Roboto;\nfontcolor=gray50;\nfontsize=\"20%\"\n\n}","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
<table class="table table" style="width: auto !important; margin-left: auto; margin-right: auto; font-size: 10px; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Label
</th>
<th style="text-align:left;">
Name
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
LM
</td>
<td style="text-align:left;">
Linear Model
</td>
</tr>
<tr>
<td style="text-align:left;">
GLM
</td>
<td style="text-align:left;">
Generalized Linear Model
</td>
</tr>
<tr>
<td style="text-align:left;">
GLMM
</td>
<td style="text-align:left;">
Generalized Linear Mixed Model
</td>
</tr>
<tr>
<td style="text-align:left;">
GAMM
</td>
<td style="text-align:left;">
Generalized Linear Mixed Model
</td>
</tr>
<tr>
<td style="text-align:left;">
OLS
</td>
<td style="text-align:left;">
Ordinary Least Squares
</td>
</tr>
<tr>
<td style="text-align:left;">
WLS
</td>
<td style="text-align:left;">
Weighted Least Squares
</td>
</tr>
<tr>
<td style="text-align:left;">
GLS
</td>
<td style="text-align:left;">
Generalized Least Squares
</td>
</tr>
<tr>
<td style="text-align:left;">
GEE
</td>
<td style="text-align:left;">
Generalized Estimating Equations
</td>
</tr>
<tr>
<td style="text-align:left;">
GMM
</td>
<td style="text-align:left;">
Generalized Method of Moments
</td>
</tr>
</tbody>
</table>
</div>
<div id="optimization" class="section level3">
<h3>Optimization</h3>
<p>So we know the goal, but how do we get to it? In practice, we typically use <em>optimization</em> methods to iteratively search for the best estimates for the parameters of a given model. The functions we explored above provide a goal- to minimize loss (however defined- least squares for continuous, classification error for binary, etc.) or maximize the likelihood (or posterior probability in the Bayesian context). Whatever the goal, an optimizing <em>algorithm</em> will typically be used to find the estimates that reach that goal. Some approaches are very general, some are better for certain types of modeling problems. These algorithms continue to make guesses until some criterion has been reached (<em>convergence</em>)<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>.</p>
<p>You generally donâ€™t need to know the details to use these algorithms to fit models, but knowing a little bit about the optimization process and available options may prove useful to deal with more complex data scenarios, where convergence can be difficult. Some packages will even have documentation specifically dealing with convergence issues. In the more predictive models previously discussed, knowing more about the optimization algorithm may speedup the time it takes to train the model, or smooth out the variability in the process.</p>
<p>As an aside, most Bayesian models use an estimation approach that is some form of <em>Markov Chain Monte Carlo</em>. It is a simulation based approach to generate subsequent estimates of parameters conditional on present estimates of them. One set of iterations is called a chain, and convergence requires multiple chains to mix well, i.e.Â come to similar conclusions about the parameter estimates. The goal even then is to maximize the log posterior distribution, similar to maximizing the likelihood. In the past this was an extremely computationally expensive procedure, but these days, modern laptops can handle even complex models with ease, though some data set sizes may be prohibitive still<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>.</p>
</div>
</div>
<div id="fitting-models" class="section level2">
<h2>Fitting Models</h2>
<p>With practically every modern modeling package in R, the two components required to fit a model are the model formula, and a data frame that contains the variables specified in that formula. Consider the following models. In general the syntax is the similar regardless of package, with special considerations for the type of model. The data argument is not included in these examples, but would be needed.</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="models.html#cb399-1"></a><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>z)                                          <span class="co"># standard linear model/OLS</span></span>
<span id="cb399-2"><a href="models.html#cb399-2"></a><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>z, <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)                    <span class="co"># logistic regression with binary response</span></span>
<span id="cb399-3"><a href="models.html#cb399-3"></a><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>z <span class="op">+</span><span class="st"> </span><span class="kw">offset</span>(<span class="kw">log</span>(q)), <span class="dt">family =</span> <span class="st">&#39;poisson&#39;</span>)    <span class="co"># count/rate model</span></span>
<span id="cb399-4"><a href="models.html#cb399-4"></a>betareg<span class="op">::</span><span class="kw">betareg</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>z)                            <span class="co"># beta regression for targets between 0 and 1</span></span>
<span id="cb399-5"><a href="models.html#cb399-5"></a>pscl<span class="op">::</span><span class="kw">hurdle</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>z, <span class="dt">dist =</span> <span class="st">&quot;negbin&quot;</span>)               <span class="co"># hurdle model with negative binomial response</span></span>
<span id="cb399-6"><a href="models.html#cb399-6"></a>lme4<span class="op">::</span><span class="kw">glmer</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>group), <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>)  <span class="co"># generalized linear mixed model</span></span>
<span id="cb399-7"><a href="models.html#cb399-7"></a>mgcv<span class="op">::</span><span class="kw">gam</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(x))                                    <span class="co"># generalized additive model</span></span>
<span id="cb399-8"><a href="models.html#cb399-8"></a>survival<span class="op">::</span><span class="kw">coxph</span>(<span class="kw">Surv</span>(<span class="dt">time =</span> t, <span class="dt">event =</span> q) <span class="op">~</span><span class="st"> </span>x)         <span class="co"># Cox Proportional Hazards Regression</span></span>
<span id="cb399-9"><a href="models.html#cb399-9"></a></span>
<span id="cb399-10"><a href="models.html#cb399-10"></a><span class="co"># Bayesian mixed model</span></span>
<span id="cb399-11"><a href="models.html#cb399-11"></a>brms<span class="op">::</span><span class="kw">brm</span>(</span>
<span id="cb399-12"><a href="models.html#cb399-12"></a>  y <span class="op">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x <span class="op">|</span><span class="st"> </span>group), </span>
<span id="cb399-13"><a href="models.html#cb399-13"></a>  <span class="dt">family =</span> <span class="st">&#39;zero_one_inflated_beta&#39;</span>, </span>
<span id="cb399-14"><a href="models.html#cb399-14"></a>  <span class="dt">prior =</span> priors</span>
<span id="cb399-15"><a href="models.html#cb399-15"></a>)</span></code></pre></div>
<p><br>
For examples of many other types of models, see this <a href="https://m-clark.github.io/R-models/">document</a>.</p>
<p>Letâ€™s finally get our hands dirty and run an example. Weâ€™ll use the world happiness dataset<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>. This is country level data based on surveys taken at various years, and the scores are averages or proportions, along with other values like GDP.</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="models.html#cb400-1"></a><span class="kw">library</span>(tidyverse)  <span class="co"># load if you haven&#39;t already</span></span>
<span id="cb400-2"><a href="models.html#cb400-2"></a></span>
<span id="cb400-3"><a href="models.html#cb400-3"></a><span class="kw">load</span>(<span class="st">&#39;data/world_happiness.RData&#39;</span>)</span>
<span id="cb400-4"><a href="models.html#cb400-4"></a></span>
<span id="cb400-5"><a href="models.html#cb400-5"></a><span class="co"># glimpse(happy)</span></span></code></pre></div>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
N
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
Min
</th>
<th style="text-align:right;">
Q1
</th>
<th style="text-align:right;">
Median
</th>
<th style="text-align:right;">
Q3
</th>
<th style="text-align:right;">
Max
</th>
<th style="text-align:right;">
% Missing
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
year
</td>
<td style="text-align:right;">
1704
</td>
<td style="text-align:right;">
2012.33
</td>
<td style="text-align:right;">
3.69
</td>
<td style="text-align:right;">
2005.00
</td>
<td style="text-align:right;">
2009.00
</td>
<td style="text-align:right;">
2012.00
</td>
<td style="text-align:right;">
2015.00
</td>
<td style="text-align:right;">
2018.00
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
life_ladder
</td>
<td style="text-align:right;">
1704
</td>
<td style="text-align:right;">
5.44
</td>
<td style="text-align:right;">
1.12
</td>
<td style="text-align:right;">
2.66
</td>
<td style="text-align:right;">
4.61
</td>
<td style="text-align:right;">
5.34
</td>
<td style="text-align:right;">
6.27
</td>
<td style="text-align:right;">
8.02
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
log_gdp_per_capita
</td>
<td style="text-align:right;">
1676
</td>
<td style="text-align:right;">
9.22
</td>
<td style="text-align:right;">
1.19
</td>
<td style="text-align:right;">
6.46
</td>
<td style="text-align:right;">
8.30
</td>
<td style="text-align:right;">
9.41
</td>
<td style="text-align:right;">
10.19
</td>
<td style="text-align:right;">
11.77
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
social_support
</td>
<td style="text-align:right;">
1691
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.12
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.83
</td>
<td style="text-align:right;">
0.90
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
healthy_life_expectancy_at_birth
</td>
<td style="text-align:right;">
1676
</td>
<td style="text-align:right;">
63.11
</td>
<td style="text-align:right;">
7.58
</td>
<td style="text-align:right;">
32.30
</td>
<td style="text-align:right;">
58.30
</td>
<td style="text-align:right;">
65.00
</td>
<td style="text-align:right;">
68.30
</td>
<td style="text-align:right;">
76.80
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
freedom_to_make_life_choices
</td>
<td style="text-align:right;">
1675
</td>
<td style="text-align:right;">
0.73
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
0.64
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.85
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
2
</td>
</tr>
<tr>
<td style="text-align:left;">
generosity
</td>
<td style="text-align:right;">
1622
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.16
</td>
<td style="text-align:right;">
-0.34
</td>
<td style="text-align:right;">
-0.12
</td>
<td style="text-align:right;">
-0.02
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
5
</td>
</tr>
<tr>
<td style="text-align:left;">
perceptions_of_corruption
</td>
<td style="text-align:right;">
1608
</td>
<td style="text-align:right;">
0.75
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.70
</td>
<td style="text-align:right;">
0.81
</td>
<td style="text-align:right;">
0.88
</td>
<td style="text-align:right;">
0.98
</td>
<td style="text-align:right;">
6
</td>
</tr>
<tr>
<td style="text-align:left;">
positive_affect
</td>
<td style="text-align:right;">
1685
</td>
<td style="text-align:right;">
0.71
</td>
<td style="text-align:right;">
0.11
</td>
<td style="text-align:right;">
0.36
</td>
<td style="text-align:right;">
0.62
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.94
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
negative_affect
</td>
<td style="text-align:right;">
1691
</td>
<td style="text-align:right;">
0.27
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.21
</td>
<td style="text-align:right;">
0.25
</td>
<td style="text-align:right;">
0.31
</td>
<td style="text-align:right;">
0.70
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
confidence_in_national_government
</td>
<td style="text-align:right;">
1530
</td>
<td style="text-align:right;">
0.48
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.33
</td>
<td style="text-align:right;">
0.46
</td>
<td style="text-align:right;">
0.61
</td>
<td style="text-align:right;">
0.99
</td>
<td style="text-align:right;">
10
</td>
</tr>
<tr>
<td style="text-align:left;">
democratic_quality
</td>
<td style="text-align:right;">
1558
</td>
<td style="text-align:right;">
-0.14
</td>
<td style="text-align:right;">
0.88
</td>
<td style="text-align:right;">
-2.45
</td>
<td style="text-align:right;">
-0.79
</td>
<td style="text-align:right;">
-0.23
</td>
<td style="text-align:right;">
0.65
</td>
<td style="text-align:right;">
1.58
</td>
<td style="text-align:right;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
delivery_quality
</td>
<td style="text-align:right;">
1559
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.98
</td>
<td style="text-align:right;">
-2.14
</td>
<td style="text-align:right;">
-0.71
</td>
<td style="text-align:right;">
-0.22
</td>
<td style="text-align:right;">
0.70
</td>
<td style="text-align:right;">
2.18
</td>
<td style="text-align:right;">
9
</td>
</tr>
<tr>
<td style="text-align:left;">
gini_index_world_bank_estimate
</td>
<td style="text-align:right;">
643
</td>
<td style="text-align:right;">
0.37
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
0.24
</td>
<td style="text-align:right;">
0.30
</td>
<td style="text-align:right;">
0.35
</td>
<td style="text-align:right;">
0.43
</td>
<td style="text-align:right;">
0.63
</td>
<td style="text-align:right;">
62
</td>
</tr>
<tr>
<td style="text-align:left;">
happiness_score
</td>
<td style="text-align:right;">
554
</td>
<td style="text-align:right;">
5.41
</td>
<td style="text-align:right;">
1.13
</td>
<td style="text-align:right;">
2.69
</td>
<td style="text-align:right;">
4.51
</td>
<td style="text-align:right;">
5.31
</td>
<td style="text-align:right;">
6.32
</td>
<td style="text-align:right;">
7.63
</td>
<td style="text-align:right;">
67
</td>
</tr>
<tr>
<td style="text-align:left;">
dystopia_residual
</td>
<td style="text-align:right;">
554
</td>
<td style="text-align:right;">
2.06
</td>
<td style="text-align:right;">
0.55
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
1.72
</td>
<td style="text-align:right;">
2.06
</td>
<td style="text-align:right;">
2.44
</td>
<td style="text-align:right;">
3.84
</td>
<td style="text-align:right;">
67
</td>
</tr>
</tbody>
</table>
<p>The happiness score itself ranges from 2.7 to 7.6, with a mean of 5.4 and standard deviation of 1.1.</p>
<p>Fitting a model with R is trivial, and at a minimum requires the two key ingredients mentioned before, the formula and data. Here we specify our target at <code>happiness_score</code> with predictors democratic quality, generosity, and GDP per capita (logged).</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="models.html#cb401-1"></a>happy_model_base =<span class="st"> </span><span class="kw">lm</span>(</span>
<span id="cb401-2"><a href="models.html#cb401-2"></a>  happiness_score <span class="op">~</span><span class="st"> </span>democratic_quality <span class="op">+</span><span class="st"> </span>generosity <span class="op">+</span><span class="st"> </span>log_gdp_per_capita,</span>
<span id="cb401-3"><a href="models.html#cb401-3"></a>  <span class="dt">data =</span> happy</span>
<span id="cb401-4"><a href="models.html#cb401-4"></a>)</span></code></pre></div>
<p>And thatâ€™s all there is to it.</p>
<div id="using-matrices" class="section level3">
<h3>Using matrices</h3>
<p>Many packages still allow for matrix input instead of specifying a model formula, or even require it (but shouldnâ€™t). This means separating data into a model (or design) matrix, and the vector or matrix of the target variable(s). For example, if we needed a speed boost and werenâ€™t concerned about some typical output we could use <span class="func" style="">lm.fit</span>.</p>
<p>First we need to create the required components. We can use <span style="func">model.matrix</span> to get what we need.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="models.html#cb402-1"></a>X =<span class="st"> </span><span class="kw">model.matrix</span>(</span>
<span id="cb402-2"><a href="models.html#cb402-2"></a>  happiness_score <span class="op">~</span><span class="st"> </span>democratic_quality <span class="op">+</span><span class="st"> </span>generosity <span class="op">+</span><span class="st"> </span>log_gdp_per_capita, </span>
<span id="cb402-3"><a href="models.html#cb402-3"></a>  <span class="dt">data =</span> happy</span>
<span id="cb402-4"><a href="models.html#cb402-4"></a>)</span>
<span id="cb402-5"><a href="models.html#cb402-5"></a></span>
<span id="cb402-6"><a href="models.html#cb402-6"></a><span class="kw">head</span>(X)</span></code></pre></div>
<pre><code>   (Intercept) democratic_quality  generosity log_gdp_per_capita
8            1         -1.8443636  0.08909068           7.500539
9            1         -1.8554263  0.05136492           7.497038
10           1         -1.8865659 -0.11219829           7.497755
19           1          0.2516293 -0.08441135           9.302960
20           1          0.2572919 -0.02068741           9.337532
21           1          0.2999450 -0.03264282           9.376145</code></pre>
<p>Note the column of ones in the model matrix <code>X</code>. This represents our intercept, but that may not mean much to you unless you understand matrix multiplication (nice demo <a href="http://matrixmultiplication.xyz/">here</a>). The other columns are just as they are in the data. Note also that the missing values have been removed.</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="models.html#cb404-1"></a><span class="kw">nrow</span>(happy)</span></code></pre></div>
<pre><code>[1] 1704</code></pre>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="models.html#cb406-1"></a><span class="kw">nrow</span>(X)</span></code></pre></div>
<pre><code>[1] 411</code></pre>
<p>The target variable must contain the same number of observations as in the model matrix, and there are various ways to create it to ensure this. Instead of <span style="func">model.matrix</span>, there is also <span style="func">model.frame</span>, which creates a data frame, with a method for extracting the corresponding target variable<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a>.</p>
<div class="sourceCode" id="cb408"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb408-1"><a href="models.html#cb408-1"></a>X_df =<span class="st"> </span><span class="kw">model.frame</span>(</span>
<span id="cb408-2"><a href="models.html#cb408-2"></a>    happiness_score <span class="op">~</span><span class="st"> </span>democratic_quality <span class="op">+</span><span class="st"> </span>generosity <span class="op">+</span><span class="st"> </span>log_gdp_per_capita,</span>
<span id="cb408-3"><a href="models.html#cb408-3"></a>    <span class="dt">data =</span> happy</span>
<span id="cb408-4"><a href="models.html#cb408-4"></a>  )</span>
<span id="cb408-5"><a href="models.html#cb408-5"></a></span>
<span id="cb408-6"><a href="models.html#cb408-6"></a>y =<span class="st"> </span><span class="kw">model.response</span>(X_df)</span></code></pre></div>
<p>We can now fit the model as follows.</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="models.html#cb409-1"></a>happy_model_matrix =<span class="st"> </span><span class="kw">lm.fit</span>(X, y)</span>
<span id="cb409-2"><a href="models.html#cb409-2"></a></span>
<span id="cb409-3"><a href="models.html#cb409-3"></a><span class="kw">summary</span>(happy_model_matrix)  <span class="co"># only a standard list is returned</span></span></code></pre></div>
<pre><code>              Length Class  Mode   
coefficients    4    -none- numeric
residuals     411    -none- numeric
effects       411    -none- numeric
rank            1    -none- numeric
fitted.values 411    -none- numeric
assign          4    -none- numeric
qr              5    qr     list   
df.residual     1    -none- numeric</code></pre>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="models.html#cb411-1"></a><span class="kw">coef</span>(happy_model_matrix)</span></code></pre></div>
<pre><code>       (Intercept) democratic_quality         generosity log_gdp_per_capita 
        -1.0104775          0.1703734          1.1608465          0.6934213 </code></pre>
<p>In my experience, it is generally a bad sign if a package requires that you create the model matrix rather than doing so itself via the standard formula + data.frame approach. I typically find that such packages tend to skip out on many other things like using typical methods like <span class="func" style="">predict</span>, <span class="func" style="">coef</span>, etc., making them even more difficult to work with. In general, the only real time you should need to use model matrices is when you are creating your own modeling package, doing simulations, utilizing model speed-ups, or otherwise know why you need them.</p>
</div>
</div>
<div id="summarizing-models" class="section level2">
<h2>Summarizing Models</h2>
<p>Once we have a model, weâ€™ll want to summarize the results of it. Most modeling packages have a <span class="func" style="">summary</span> method we can apply, which will provide parameter estimates, some notion of model fit, inferential statistics, and other output.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="models.html#cb413-1"></a>happy_model_base_sum =<span class="st"> </span><span class="kw">summary</span>(happy_model_base)</span></code></pre></div>
<pre><code>
Call:
lm(formula = happiness_score ~ democratic_quality + generosity + 
    log_gdp_per_capita, data = happy)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.75376 -0.45585 -0.00307  0.46013  1.69925 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        -1.01048    0.31436  -3.214 0.001412 ** 
democratic_quality  0.17037    0.04588   3.714 0.000233 ***
generosity          1.16085    0.19548   5.938 6.18e-09 ***
log_gdp_per_capita  0.69342    0.03335  20.792  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.6283 on 407 degrees of freedom
  (1293 observations deleted due to missingness)
Multiple R-squared:  0.6953,    Adjusted R-squared:  0.6931 
F-statistic: 309.6 on 3 and 407 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>There is a lot of info to parse there, so weâ€™ll go over some of it in particular. The summary provides several pieces of information: the coefficients or weights (<code>Estimate</code>)<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a>, the standard errors (<code>Std. Error</code>), the t-statistic (which is just the coefficient divided by the standard error), and the corresponding p-value. The main thing to look at are the actual coefficients and the direction of their relationship, positive or negative. For example, with regard to the effect of democratic quality, moving one point on democratic quality results in roughly 0.2 units of happiness. Is this a notable effect? Knowing the scale of the outcome can help us understand the magnitude of the effect in a general sense. Before we showed that the standard deviation of the happiness scale was 1.1. So, in terms of standard deviation units- moving 1 points on democratic quality would result in a 0.2 standard deviation increase in state-level happiness. We might consider this fairly small, but maybe not negligible.</p>
<p>One thing we must also have in order to understand our results is to get a sense of the uncertainty in the effects. The following provides confidence intervals for each of the coefficients.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="models.html#cb415-1"></a><span class="kw">confint</span>(happy_model_base)</span></code></pre></div>
<pre><code>                         2.5 %     97.5 %
(Intercept)        -1.62845472 -0.3925003
democratic_quality  0.08018814  0.2605586
generosity          0.77656244  1.5451306
log_gdp_per_capita  0.62786210  0.7589806</code></pre>
<p>Now we have a sense of the range of plausible values for the coefficients. The value we actually estimate is the best guess given our circumstances, but slight changes in the data, the way we collect it, the time we collect it, etc., all would result in a slightly different result. The confidence interval provides a range of what we could expect given the uncertainty, and, given its importance, you should always report it. In fact, just showing the coefficient and the interval would be better than typical reporting of the statistical test results, though you can do both.</p>
</div>
<div id="variable-transformations" class="section level2">
<h2>Variable Transformations</h2>
<p>Transforming variables can provide a few benefits in modeling, whether applied to the target, covariates, or both, and should regularly be used for most models. Some of these benefits include<a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a>:</p>
<ul>
<li>Interpretable intercepts</li>
<li>More comparable covariate effects</li>
<li>Faster estimation</li>
<li>Easier convergence</li>
<li>Help with heteroscedasticity</li>
</ul>
<p>For example, merely centering predictor variables, i.e.Â subtracting the mean, provides a more interpretable intercept that will fall within the actual range of the target variable, telling us what the value of the target variable is when the covariates are at their means (or reference value if categorical).</p>
<div id="numeric-variables" class="section level3">
<h3>Numeric variables</h3>
<p>The following table shows the interpretation of two extremely common transformations applied to numeric variables- logging and scaling (i.e.Â standardizing to mean zero, standard deviation one).</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
target
</th>
<th style="text-align:left;">
predictor
</th>
<th style="text-align:left;">
interpretation
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
y
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:left;">
<span class="math inline">\(\Delta y = \beta\Delta x\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
y
</td>
<td style="text-align:left;">
log(x)
</td>
<td style="text-align:left;">
<span class="math inline">\(\Delta y \approx (\beta/100)\%\Delta x\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
log(y)
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:left;">
<span class="math inline">\(\%\Delta y \approx 100\cdot \beta\%\Delta x\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
log(y)
</td>
<td style="text-align:left;">
log(x)
</td>
<td style="text-align:left;">
<span class="math inline">\(\%\Delta y = \beta\%\Delta x\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
y
</td>
<td style="text-align:left;">
scale(x)
</td>
<td style="text-align:left;">
<span class="math inline">\(\Delta y = \beta\sigma\Delta x\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
scale(y)
</td>
<td style="text-align:left;">
x
</td>
<td style="text-align:left;">
<span class="math inline">\(\sigma\Delta y = \beta\Delta x\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;">
scale(y)
</td>
<td style="text-align:left;">
scale(x)
</td>
<td style="text-align:left;">
<span class="math inline">\(\sigma\Delta y = \beta\sigma\Delta x\)</span>
</td>
</tr>
</tbody>
</table>
<p>For example, to start with the normal linear model situation, a one-unit change in <span class="math inline">\(x\)</span>, i.e.Â <span class="math inline">\(\Delta x =1\)</span>, leads to <span class="math inline">\(\beta\)</span> unit change in <span class="math inline">\(y\)</span>. If we log the target variable <span class="math inline">\(y\)</span>, the interpretation of the coefficient for <span class="math inline">\(x\)</span> is that a one-unit change in <span class="math inline">\(x\)</span> leads to an (approximately) 100<span class="math inline">\(\cdot\)</span><span class="math inline">\(\beta\)</span>% change in <span class="math inline">\(y\)</span>. The 100 changes the result from a proportion to percentage change. More concretely, if <span class="math inline">\(\beta\)</span> was .5, a unit change in <span class="math inline">\(x\)</span> leads to (roughly) a 50% change in <span class="math inline">\(y\)</span>. If both were logged, a percentage change in <span class="math inline">\(x\)</span> leads to a <span class="math inline">\(\beta\)</span> percentage change in y<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a>. These percentage change interpretations are called <a href="https://en.wikipedia.org/wiki/Elasticity_(economics)">elasticities</a> in econometrics and areas trained similarly<a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a>.</p>
<p>It is very common to use <em>standardized</em> variables as well, also called normalizing, or simply scaling. If <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> are both standardized, a one unit (i.e.Â one standard deviation) change in <span class="math inline">\(x\)</span> leads to a <span class="math inline">\(\beta\)</span> standard deviation change in <span class="math inline">\(y\)</span>. Again, if <span class="math inline">\(\beta\)</span> was .5, a standard deviation change in <span class="math inline">\(x\)</span> leads to a half standard deviation change in <span class="math inline">\(y\)</span>. In general, there is nothing to lose by standardizing, so you should employ it often.</p>
<p>Another common transformation, particularly in machine learning, is the <em>min-max normalization</em>, changing variables to range from some minimum to some maximum, usually zero to one.</p>
</div>
<div id="categorical-variables" class="section level3">
<h3>Categorical variables</h3>
<p>A raw character string is not an analyzable unit, so character strings and labeled variables like factors must be converted for analysis to be conducted on them. For categorical variables, we can employ what is called <em>effects coding</em> to test for specific types of group differences. Far and away the most common approach is called <em>dummy coding</em> or <em>one-hot encoding</em><a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a>. In the next example, we will use dummy coding via the recipes package. I also to show how to standardize a numeric variable as previously discussed.</p>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="models.html#cb417-1"></a><span class="kw">library</span>(recipes)</span>
<span id="cb417-2"><a href="models.html#cb417-2"></a></span>
<span id="cb417-3"><a href="models.html#cb417-3"></a>nafta =<span class="st"> </span>happy <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb417-4"><a href="models.html#cb417-4"></a><span class="st">  </span><span class="kw">filter</span>(country <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;United States&#39;</span>, <span class="st">&#39;Canada&#39;</span>, <span class="st">&#39;Mexico&#39;</span>))</span>
<span id="cb417-5"><a href="models.html#cb417-5"></a></span>
<span id="cb417-6"><a href="models.html#cb417-6"></a>dummy =<span class="st"> </span>nafta  <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb417-7"><a href="models.html#cb417-7"></a><span class="st">  </span><span class="kw">recipe</span>(<span class="op">~</span><span class="st"> </span>country <span class="op">+</span><span class="st"> </span>generosity) <span class="op">%&gt;%</span><span class="st">        </span><span class="co"># formula approach for specifying variables</span></span>
<span id="cb417-8"><a href="models.html#cb417-8"></a><span class="st">  </span><span class="kw">step_dummy</span>(country, <span class="dt">one_hot =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st">   </span><span class="co"># make variables for all factor levels</span></span>
<span id="cb417-9"><a href="models.html#cb417-9"></a><span class="st">  </span><span class="kw">step_center</span>(generosity) <span class="op">%&gt;%</span><span class="st">               </span><span class="co"># example of centering</span></span>
<span id="cb417-10"><a href="models.html#cb417-10"></a><span class="st">  </span><span class="kw">step_scale</span>(generosity)                    <span class="co"># example of standardizing</span></span>
<span id="cb417-11"><a href="models.html#cb417-11"></a></span>
<span id="cb417-12"><a href="models.html#cb417-12"></a><span class="kw">prep</span>(dummy) <span class="op">%&gt;%</span><span class="st">      </span><span class="co"># estimates the necessary data to apply to this or other data sets</span></span>
<span id="cb417-13"><a href="models.html#cb417-13"></a><span class="st">  </span><span class="kw">bake</span>(nafta) <span class="op">%&gt;%</span><span class="st">    </span><span class="co"># apply the computations</span></span>
<span id="cb417-14"><a href="models.html#cb417-14"></a><span class="st">  </span><span class="kw">print</span>(<span class="dt">n =</span> <span class="dv">20</span>)</span></code></pre></div>
<pre><code># A tibble: 39 x 4
   generosity country_Canada country_Mexico country_United.States
        &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;                 &lt;dbl&gt;
 1     0.835               1              0                     0
 2     0.819               1              0                     0
 3     0.891               1              0                     0
 4     0.801               1              0                     0
 5     0.707               1              0                     0
 6     0.841               1              0                     0
 7     1.06                1              0                     0
 8     1.21                1              0                     0
 9     0.940               1              0                     0
10     0.838               1              0                     0
11     0.590               1              0                     0
12     0.305               1              0                     0
13    -0.0323              1              0                     0
14    NA                   0              1                     0
15    -1.19                0              1                     0
16    -1.39                0              1                     0
17    -1.08                0              1                     0
18    -0.915               0              1                     0
19    -1.22                0              1                     0
20    -1.18                0              1                     0
# â€¦ with 19 more rows</code></pre>
<p>We see that the first few observations are Canada, and the next few Mexico. Note that doing this is rarely required for most modeling situations, but even if not, it sometimes can be useful to do so explicitly. If your modeling package cannot handle factor variables, and thus requires explicit coding, youâ€™ll know, and typically these are the same ones that require matrix input.</p>
<p>Letâ€™s run a regression as follows to show how it would happen automatically.</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="models.html#cb419-1"></a>model_dummy =<span class="st"> </span><span class="kw">lm</span>(happiness_score <span class="op">~</span><span class="st"> </span>country, <span class="dt">data =</span> nafta)</span>
<span id="cb419-2"><a href="models.html#cb419-2"></a></span>
<span id="cb419-3"><a href="models.html#cb419-3"></a><span class="kw">summary</span>(model_dummy)</span></code></pre></div>
<pre><code>
Call:
lm(formula = happiness_score ~ country, data = nafta)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.26960 -0.07453 -0.00615  0.06322  0.42920 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)           7.36887    0.09633  76.493 5.64e-14 ***
countryMexico        -0.61107    0.13624  -4.485  0.00152 ** 
countryUnited States -0.34337    0.13624  -2.520  0.03275 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.1927 on 9 degrees of freedom
  (27 observations deleted due to missingness)
Multiple R-squared:  0.692, Adjusted R-squared:  0.6236 
F-statistic: 10.11 on 2 and 9 DF,  p-value: 0.004994</code></pre>
<p>In this case, the coefficient represents the difference in means on the target variable between the reference group and the group in question. In this case, the U.S. is -0.34 less on the happy score than the reference country (Canada). The intercept tells us the mean of the reference group.</p>
<p>Other codings are possible, and these would allow for specific group comparisons or types of comparisons. This is sometimes called <em>contrast coding</em>. For example, we could compare Canada vs.Â both the U.S. and Mexico. By giving Canada twice the weight of the other two we can get this result. I also add a coding that will just compare Mexico vs.Â the U.S. The actual weights used are arbitrary, but in this case should sum to zero.</p>
<table class="table" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
group
</th>
<th style="text-align:right;">
canada_vs_other
</th>
<th style="text-align:right;">
mexico_vs_us
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Canada
</td>
<td style="text-align:right;">
-0.667
</td>
<td style="text-align:right;">
0.0
</td>
</tr>
<tr>
<td style="text-align:left;">
Mexico
</td>
<td style="text-align:right;">
0.333
</td>
<td style="text-align:right;">
-0.5
</td>
</tr>
<tr>
<td style="text-align:left;">
United States
</td>
<td style="text-align:right;">
0.333
</td>
<td style="text-align:right;">
0.5
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; border:0;" colspan="100%">
<sup></sup> weights sum to zero, but are arbitrary
</td>
</tr>
</tfoot>
</table>
<p>Adding such coding to a factor variable allows the corresponding models to use it in constructing the model matrix, rather than dummy coding. See the group means and calculate the results by hand for yourself.</p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="models.html#cb421-1"></a>nafta =<span class="st"> </span>nafta <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb421-2"><a href="models.html#cb421-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">country_fac =</span> <span class="kw">factor</span>(country))</span>
<span id="cb421-3"><a href="models.html#cb421-3"></a></span>
<span id="cb421-4"><a href="models.html#cb421-4"></a><span class="kw">contrasts</span>(nafta<span class="op">$</span>country_fac) =<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">0</span>, <span class="fl">-.5</span>, <span class="fl">.5</span>), </span>
<span id="cb421-5"><a href="models.html#cb421-5"></a>                                      <span class="dt">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb421-6"><a href="models.html#cb421-6"></a></span>
<span id="cb421-7"><a href="models.html#cb421-7"></a><span class="kw">summary</span>(<span class="kw">lm</span>(happiness_score <span class="op">~</span><span class="st"> </span>country_fac, <span class="dt">data =</span> nafta))</span></code></pre></div>
<pre><code>
Call:
lm(formula = happiness_score ~ country_fac, data = nafta)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.26960 -0.07453 -0.00615  0.06322  0.42920 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   7.05072    0.05562 126.769 6.01e-16 ***
country_fac1 -0.47722    0.11799  -4.045  0.00291 ** 
country_fac2  0.26770    0.13624   1.965  0.08100 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.1927 on 9 degrees of freedom
  (27 observations deleted due to missingness)
Multiple R-squared:  0.692, Adjusted R-squared:  0.6236 
F-statistic: 10.11 on 2 and 9 DF,  p-value: 0.004994</code></pre>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="models.html#cb423-1"></a>nafta <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb423-2"><a href="models.html#cb423-2"></a><span class="st">  </span><span class="kw">group_by</span>(country) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb423-3"><a href="models.html#cb423-3"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">happy =</span> <span class="kw">mean</span>(happiness_score, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>))</span></code></pre></div>
<pre><code># A tibble: 3 x 2
  country       happy
  &lt;chr&gt;         &lt;dbl&gt;
1 Canada         7.37
2 Mexico         6.76
3 United States  7.03</code></pre>
<p>For example, we can see that for this balanced data set, the <code>_fac1</code> coefficient is the average of the U.S. and Mexico coefficients that we got from dummy coding, which represented their respective mean differences from Canada: (-0.611 + -0.343) / 2 = -0.477. The <code>_fac2</code> coefficient is just the U.S. Mexico mean difference, as expected.</p>
<p>In other circumstances, we can use <em>categorical embeddings</em> to reduce a very large number of categorical levels to a smaller number of numeric variables. This is very commonly employed in deep learning.</p>
</div>
<div id="scales-indices-and-dimension-reduction" class="section level3">
<h3>Scales, indices, and dimension reduction</h3>
<p>It is often the case that we have several correlated variables/items which do not all need to go into the model. For example, instead of using all items in a psychological scale, we can use the scale score, however defined, which is often just a <em>sum score</em> of the underlying items. Often people will create an index by using a <em>principal components analysis</em>, which can be thought of as a means to create a weighted sum score, or set of scores. Some (especially binary) items may tend toward the creation of a single variable that simply notes whether any of those collection of variables was present or not.</p>
<div id="two-step-approaches" class="section level4">
<h4>Two-step approaches</h4>
<p>Some might do a preliminary analysis, such as a <em>cluster analysis</em> or <em>factor analysis</em>, to create new target or predictor variables. In the former we reduce several variables to a single categorical label. Factor analysis does the same but results in a more expressive continuous metric. While fine to use, the corresponding results are measured with error, so treating the categories or factor scores as you would observed variables will typically result in optimistic results when you later include them in a subsequent analysis like a linear regression. Though this difference is probably slight in most applications, keen reviewers would probably point out the model shortcoming.</p>
</div>
</div>
<div id="dont-discretize" class="section level3">
<h3>Donâ€™t discretize</h3>
<p>Little pains advanced modelers more than seeing results where a nice expressive continuous metric is butchered into two categories (e.g.Â taking a numeric age and collapsing to â€˜oldâ€™ vs.Â â€˜youngâ€™). There is rarely a reason to do this, and it is difficult to justify. There are reasons to collapse rare labels of a categorical variable, so that the new variable has fewer but more frequent categories. For example, data may have five or six race categories, but often the values are lumped into majority group vs.Â minority group due to each minority category having too few observations. But even that can cause problems, and doesnâ€™t really overcome the fact that you simply didnâ€™t have enough data to begin with.</p>
</div>
</div>
<div id="variable-importance" class="section level2">
<h2>Variable Importance</h2>
<p>In many circumstances, one of the modeling goals is to determine which predictor variable is most important out of the collection used in the model, or otherwise rank order the effectiveness of the predictors in some fashion. However, determining relative <em>variable importance</em> is at best an approximation with some methods, and a fairly hopeless endeavor with others. For just basic linear regression there are many methods that would not necessarily come to the same conclusions. Statistical significance, e.g.Â the Z/t statistic or p-value, is simply not a correct way to do so. Some believe that <a href="models.html#numeric-variables">standardizing numeric variables</a> is enough, but it is not, and doesnâ€™t help with comparison to categorical inputs. In addition, if youâ€™re model is not strong, it doesnâ€™t make much sense to even worry about which is the best of a bad lot.</p>
<p>Another reason that â€˜importanceâ€™ is a problematic endeavor is that a statistical result doesnâ€™t speak to practical action, nor does it speak to the fact that small effects may be very important. Sex may be an important driver in social science model, but we may not be able to do anything about it for many outcomes that may be of interest. With health outcomes, any effects might be worthy of attention, however small, if they could practically increase the likelihood of survival.</p>
<p>Even if you can come up with a metric you like, you would still need some measure of uncertainty around that to make a claim that one predictor is reasonably better than another, and the only real approach to do that is usually some computationally expensive procedure that you will likely have to put together by hand.</p>
<p>As an example, for standard linear regression there are many methods that decompose <span class="math inline">\(R^2\)</span> into relative contributions by the covariates. The tools to do so have to re-run the model in many ways to produce these estimates (see the <span class="pack" style="">relaimpo</span> package for example), but you would then have to use bootstrapping or similar approach to get interval estimates for those measures of importance. Certain techniques like random forests have a natural way to provide variable importance metrics, but providing inference on them would similarly be very computationally expensive.</p>
<p>In the end though, I think it is probably best to assume that any effect that seems practically distinct from zero might be worthy of attention, and can be regarded for its own sake. The more actionable, the better.</p>
</div>
<div id="extracting-output" class="section level2">
<h2>Extracting Output</h2>
<p>The better you get at modeling, the more often you are going to need to get at certain parts of the model output easily. For example, we can extract the coefficients, residuals, model data and other parts from standard linear model objects from base R.</p>
<p>Why would you want to do this? A simple example would be to compare effects across different settings. We can collect the values, put them in a data frame, and then to a table or visualization.</p>
<p>Typical modeling <a href="programming.html#methods">methods</a> you might want to use:</p>
<ul>
<li><span class="func" style="">summary</span>: print results in a legible way</li>
<li><span class="func" style="">plot</span>: plot something about the model (e.g.Â diagnostic plots)</li>
<li><span class="func" style="">predict</span>: make predictions, possibly on new data</li>
<li><span class="func" style="">confint</span>: get confidence intervals for parameters</li>
<li><span class="func" style="">coef</span>: extract coefficients</li>
<li><span class="func" style="">fitted</span>: extract fitted values</li>
<li><span class="func" style="">residuals</span>: extract residuals</li>
<li><span class="func" style="">AIC</span>: extract AIC</li>
</ul>
<p>Here is an example of using the <span class="func" style="">predict</span> and <span class="func" style="">coef</span> methods.</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="models.html#cb425-1"></a><span class="kw">predict</span>(happy_model_base, <span class="dt">newdata =</span> happy <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>))</span></code></pre></div>
<pre><code>       1        2        3        4        5 
3.838179 3.959046 3.928180 4.004129 4.171624 </code></pre>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="models.html#cb427-1"></a><span class="kw">coef</span>(happy_model_base)</span></code></pre></div>
<pre><code>       (Intercept) democratic_quality         generosity log_gdp_per_capita 
        -1.0104775          0.1703734          1.1608465          0.6934213 </code></pre>
<p>Also, itâ€™s useful to assign the summary results to an object, so that you can extract things that are also useful but would not be in the model object. We did this before, so now letâ€™s take a look.</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="models.html#cb429-1"></a><span class="kw">str</span>(happy_model_base_sum, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>List of 12
 $ call         : language lm(formula = happiness_score ~ democratic_quality + generosity + log_gdp_per_capita, data = happy)
 $ terms        :Classes &#39;terms&#39;, &#39;formula&#39;  language happiness_score ~ democratic_quality + generosity + log_gdp_per_capita
  .. ..- attr(*, &quot;variables&quot;)= language list(happiness_score, democratic_quality, generosity, log_gdp_per_capita)
  .. ..- attr(*, &quot;factors&quot;)= int [1:4, 1:3] 0 1 0 0 0 0 1 0 0 0 ...
  .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2
  .. ..- attr(*, &quot;term.labels&quot;)= chr [1:3] &quot;democratic_quality&quot; &quot;generosity&quot; &quot;log_gdp_per_capita&quot;
  .. ..- attr(*, &quot;order&quot;)= int [1:3] 1 1 1
  .. ..- attr(*, &quot;intercept&quot;)= int 1
  .. ..- attr(*, &quot;response&quot;)= int 1
  .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; 
  .. ..- attr(*, &quot;predvars&quot;)= language list(happiness_score, democratic_quality, generosity, log_gdp_per_capita)
  .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:4] &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot;
  .. .. ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;happiness_score&quot; &quot;democratic_quality&quot; &quot;generosity&quot; &quot;log_gdp_per_capita&quot;
 $ residuals    : Named num [1:411] -0.405 -0.572 0.057 -0.426 -0.829 ...
  ..- attr(*, &quot;names&quot;)= chr [1:411] &quot;8&quot; &quot;9&quot; &quot;10&quot; &quot;19&quot; ...
 $ coefficients : num [1:4, 1:4] -1.01 0.17 1.161 0.693 0.314 ...
  ..- attr(*, &quot;dimnames&quot;)=List of 2
 $ aliased      : Named logi [1:4] FALSE FALSE FALSE FALSE
  ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;(Intercept)&quot; &quot;democratic_quality&quot; &quot;generosity&quot; &quot;log_gdp_per_capita&quot;
 $ sigma        : num 0.628
 $ df           : int [1:3] 4 407 4
 $ r.squared    : num 0.695
 $ adj.r.squared: num 0.693
 $ fstatistic   : Named num [1:3] 310 3 407
  ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;value&quot; &quot;numdf&quot; &quot;dendf&quot;
 $ cov.unscaled : num [1:4, 1:4] 0.2504 0.0229 -0.0139 -0.0264 0.0229 ...
  ..- attr(*, &quot;dimnames&quot;)=List of 2
 $ na.action    : &#39;omit&#39; Named int [1:1293] 1 2 3 4 5 6 7 11 12 13 ...
  ..- attr(*, &quot;names&quot;)= chr [1:1293] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
 - attr(*, &quot;class&quot;)= chr &quot;summary.lm&quot;</code></pre>
<p>If we want the adjusted <span class="math inline">\(R^2\)</span> or root mean squared error (RMSE, i.e.Â average error<a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a>), they arenâ€™t readily available in the model object, but they are in the summary object, so we can pluck them out as we would any other <a href="data_structures.html#lists">list object</a>.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="models.html#cb431-1"></a>happy_model_base_sum<span class="op">$</span>adj.r.squared</span></code></pre></div>
<pre><code>[1] 0.6930647</code></pre>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="models.html#cb433-1"></a>happy_model_base_sum[[<span class="st">&#39;sigma&#39;</span>]]</span></code></pre></div>
<pre><code>[1] 0.6282718</code></pre>
<div id="package-support" class="section level3">
<h3>Package support</h3>
<p>There are many packages available to get at model results. One of the more widely used is <span class="pack" style="">broom</span>, which has <span class="func" style="">tidy</span> and other functions that can apply in different ways to different models depending on their class.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="models.html#cb435-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb435-2"><a href="models.html#cb435-2"></a><span class="kw">tidy</span>(happy_model_base)</span></code></pre></div>
<pre><code># A tibble: 4 x 5
  term               estimate std.error statistic  p.value
  &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
1 (Intercept)          -1.01     0.314      -3.21 1.41e- 3
2 democratic_quality    0.170    0.0459      3.71 2.33e- 4
3 generosity            1.16     0.195       5.94 6.18e- 9
4 log_gdp_per_capita    0.693    0.0333     20.8  5.93e-66</code></pre>
<p>Some packages will produce tables for a model object that are more or less ready for publication. However, unless you know itâ€™s in the exact style you need, youâ€™re probably better off dealing with it yourself. For example, you can use <span class="func" style="">tidy</span> and do minor cleanup to get the table ready for publication.</p>
</div>
</div>
<div id="visualization" class="section level2">
<h2>Visualization</h2>
<blockquote>
<p>Models require visualization to be understood completely.</p>
</blockquote>
<p>If you arenâ€™t using visualization as a fundamental part of your model exploration, youâ€™re likely leaving a lot of that exploration behind, and not communicating the results as well as you could to the broadest audience possible. When adding nonlinear effects, interactions, and more, visualization is a must. Thankfully there are many packages to help you get data you need to visualize effects.</p>
<p>We start with the <span class="pack" style="">emmeans</span> package. In the following example we have a country effect, and wish to get the mean happiness scores per country. We then visualize the results. Here we can see that Mexico is lowest on average.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="models.html#cb437-1"></a>happy_model_nafta =<span class="st"> </span><span class="kw">lm</span>(happiness_score <span class="op">~</span><span class="st"> </span>country <span class="op">+</span><span class="st"> </span>year, <span class="dt">data =</span> nafta)</span>
<span id="cb437-2"><a href="models.html#cb437-2"></a></span>
<span id="cb437-3"><a href="models.html#cb437-3"></a><span class="kw">library</span>(emmeans)</span>
<span id="cb437-4"><a href="models.html#cb437-4"></a>country_means =<span class="st"> </span><span class="kw">emmeans</span>(happy_model_nafta, <span class="op">~</span><span class="st"> </span>country)</span>
<span id="cb437-5"><a href="models.html#cb437-5"></a>country_means</span></code></pre></div>
<pre><code> country       emmean    SE df lower.CL upper.CL
 Canada          7.37 0.064  8     7.22     7.52
 Mexico          6.76 0.064  8     6.61     6.91
 United States   7.03 0.064  8     6.88     7.17

Confidence level used: 0.95 </code></pre>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="models.html#cb439-1"></a><span class="kw">plot</span>(country_means)</span></code></pre></div>
<p><img src="practical-data-science_files/figure-html/emmeans-1.svg" width="75%" style="display: block; margin: auto;" /></p>
<p>We can also test for pairwise differences between the countries, and thereâ€™s no reason not to visualize that also. In the following, after adjustment Mexico and U.S. might not differ on mean happiness, but the other comparisons are statistically notable<a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a>.</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="models.html#cb440-1"></a>pw_comparisons =<span class="st"> </span><span class="kw">contrast</span>(country_means, <span class="dt">method =</span> <span class="st">&#39;pairwise&#39;</span>, <span class="dt">adjust =</span> <span class="st">&#39;bonferroni&#39;</span>)</span>
<span id="cb440-2"><a href="models.html#cb440-2"></a>pw_comparisons</span></code></pre></div>
<pre><code> contrast               estimate     SE df t.ratio p.value
 Canada - Mexico           0.611 0.0905  8  6.751  0.0004 
 Canada - United States    0.343 0.0905  8  3.793  0.0159 
 Mexico - United States   -0.268 0.0905  8 -2.957  0.0547 

P value adjustment: bonferroni method for 3 tests </code></pre>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="models.html#cb442-1"></a><span class="kw">plot</span>(pw_comparisons)</span></code></pre></div>
<p><img src="practical-data-science_files/figure-html/emmeans-pairwise-1.svg" width="75%" style="display: block; margin: auto;" /></p>
<p>The following example uses <span class="pack" style="">ggeffects</span>. First, we run a model with an interaction of country and year (weâ€™ll talk more about interactions later). Then we get predictions for the year by country, and subsequently visualize. We can see that the trend, while negative for all countries, is more pronounced as we move south.</p>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="models.html#cb443-1"></a>happy_model_nafta =<span class="st"> </span><span class="kw">lm</span>(happiness_score <span class="op">~</span><span class="st"> </span>year<span class="op">*</span>country, <span class="dt">data =</span> nafta)</span>
<span id="cb443-2"><a href="models.html#cb443-2"></a></span>
<span id="cb443-3"><a href="models.html#cb443-3"></a><span class="kw">library</span>(ggeffects)</span>
<span id="cb443-4"><a href="models.html#cb443-4"></a>preds =<span class="st"> </span><span class="kw">ggpredict</span>(happy_model_nafta, <span class="dt">terms =</span> <span class="kw">c</span>(<span class="st">&#39;year&#39;</span>, <span class="st">&#39;country&#39;</span>))</span>
<span id="cb443-5"><a href="models.html#cb443-5"></a></span>
<span id="cb443-6"><a href="models.html#cb443-6"></a><span class="kw">plot</span>(preds)</span></code></pre></div>
<p><img src="practical-data-science_files/figure-html/ggeffects-1.svg" width="75%" style="display: block; margin: auto;" /></p>
<p>Whenever you move to generalized linear models or other more complicated settings, visualization is even more important, so itâ€™s best to have some tools at your disposal.</p>
</div>
<div id="extensions-to-the-standard-linear-model" class="section level2">
<h2>Extensions to the Standard Linear Model</h2>
<div id="different-types-of-targets" class="section level3">
<h3>Different types of targets</h3>
<p>In many data situations, we do not have a continuous numeric target variable, or may want to use a different distribution to get a better fit, or adhere to some theoretical perspective. For example, count data is not continuous and often notably skewed, so assuming a normal symmetric distribution may not work as well. From a data generating perspective we can use the Poisson distribution<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a> for the target variable instead.</p>
<p><span class="math display">\[\ln{\mu} =  X\beta\]</span>
<span class="math display">\[\mu = e^{X\beta}\]</span>
<span class="math display">\[y \sim \mathcal{Pois}(\mu)\]</span>
Conceptually nothing has really changed from what we were doing with the standard linear model, except for the distribution. We still have a mean function determined by our predictors, and this is what weâ€™re typically mainly interested in from a theoretical perspective. We do have an added step, a transformation of the mean (now usually called the <em>linear predictor</em>). Poisson naturally works with the log of the target, but rather than do that explicitly, we instead exponentiate the linear predictor. The <em>link function</em><a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>, which is the natural log in this setting, has a corresponding <em>inverse link</em> (or mean function)- exponentiation.</p>
<p>In code we can demonstrate this as follows.</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="models.html#cb444-1"></a><span class="kw">set.seed</span>(<span class="dv">123</span>)                     <span class="co"># for reproducibility</span></span>
<span id="cb444-2"><a href="models.html#cb444-2"></a>N =<span class="st"> </span><span class="dv">1000</span>                          <span class="co"># sample size</span></span>
<span id="cb444-3"><a href="models.html#cb444-3"></a>beta =<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>)                    <span class="co"># the true coefficient values</span></span>
<span id="cb444-4"><a href="models.html#cb444-4"></a>x =<span class="st"> </span><span class="kw">rnorm</span>(N)                      <span class="co"># a single predictor variable</span></span>
<span id="cb444-5"><a href="models.html#cb444-5"></a>mu =<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>beta[<span class="dv">2</span>]<span class="op">*</span>x)     <span class="co"># the linear predictor</span></span>
<span id="cb444-6"><a href="models.html#cb444-6"></a>y =<span class="st"> </span><span class="kw">rpois</span>(N, <span class="dt">lambda =</span> mu)         <span class="co"># the target variable lambda = mean</span></span>
<span id="cb444-7"><a href="models.html#cb444-7"></a></span>
<span id="cb444-8"><a href="models.html#cb444-8"></a><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">family =</span> poisson)</span></code></pre></div>
<pre><code>
Call:  glm(formula = y ~ x, family = poisson)

Coefficients:
(Intercept)            x  
      2.009        0.994  

Degrees of Freedom: 999 Total (i.e. Null);  998 Residual
Null Deviance:      13240 
Residual Deviance: 1056     AIC: 4831</code></pre>
<p>A very common setting is the case where our target variable takes on only two values- yes vs.Â no, alive vs.Â dead, etc. The most common model used in such settings is the logistic regression model. In this case, it will have a different link to go with a different distribution.</p>
<p><span class="math display">\[\ln{\frac{\mu}{1-\mu}} =  X\beta\]</span>
<span class="math display">\[\mu = \frac{1}{1+e^{-X\beta}}\]</span>
<span class="math display">\[y \sim \mathcal{Binom}(\mathrm{prob}=\mu, \mathrm{size} = 1)\]</span>
Here our link function is called the <em>logit</em>, and itâ€™s inverse takes our linear predictor and puts it on the probability scale.</p>
<p>Again, some code can help drive this home.</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="models.html#cb446-1"></a>mu =<span class="st"> </span><span class="kw">plogis</span>(beta[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>beta[<span class="dv">2</span>]<span class="op">*</span>x)</span>
<span id="cb446-2"><a href="models.html#cb446-2"></a>y =<span class="st"> </span><span class="kw">rbinom</span>(N, <span class="dt">size =</span> <span class="dv">1</span>, mu)</span>
<span id="cb446-3"><a href="models.html#cb446-3"></a></span>
<span id="cb446-4"><a href="models.html#cb446-4"></a><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">family =</span> binomial)</span></code></pre></div>
<pre><code>
Call:  glm(formula = y ~ x, family = binomial)

Coefficients:
(Intercept)            x  
      2.141        1.227  

Degrees of Freedom: 999 Total (i.e. Null);  998 Residual
Null Deviance:      852.3 
Residual Deviance: 708.8    AIC: 712.8</code></pre>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="models.html#cb448-1"></a><span class="co"># extension to count/proportional model</span></span>
<span id="cb448-2"><a href="models.html#cb448-2"></a><span class="co"># mu = plogis(beta[1] + beta[2]*x)</span></span>
<span id="cb448-3"><a href="models.html#cb448-3"></a><span class="co"># total = rpois(N, lambda = 5)</span></span>
<span id="cb448-4"><a href="models.html#cb448-4"></a><span class="co"># events = rbinom(N, size = total, mu)</span></span>
<span id="cb448-5"><a href="models.html#cb448-5"></a><span class="co"># nonevents = total - events</span></span>
<span id="cb448-6"><a href="models.html#cb448-6"></a><span class="co"># </span></span>
<span id="cb448-7"><a href="models.html#cb448-7"></a><span class="co"># glm(cbind(events, nonevents) ~ x, family = binomial)</span></span></code></pre></div>
<p>Youâ€™ll have noticed that when we fit these models we used <span class="func" style="">glm</span> instead of <span class="func" style="">lm</span>. The normal linear model is a special case of <em>generalized linear models</em>, which includes a specific class of distributions - normal, poisson, binomial, gamma, beta and more - collectively referred to as the <a href="https://en.wikipedia.org/wiki/Exponential_family">exponential family</a>. While this family can cover a lot of ground, you do not have to restrict yourself to it, and many R modeling packages will provide easy access to more. The main point is that you have tools to deal with continuous, binary, count, ordinal, and other types of data. Furthermore, not much necessarily changes conceptually from model to model besides the link function and/or distribution.</p>
</div>
<div id="correlated-data" class="section level3">
<h3>Correlated data</h3>
<p>Often in standard regression modeling situations we have data that is correlated, like when we observe multiple observations for individuals (e.g.Â longitudinal studies), or observations are clustered within geographic units. There are many ways to analyze all kinds of correlated data in the form of clustered data, time series, spatial data and similar. In terms of understanding the mean function and data generating distribution for our target variable, as we did in our previous models, not much changes. However, we will want to utilize estimation techniques that take this correlation into account. Examples of such models include:</p>
<ul>
<li>Mixed models (e.g.Â random intercepts, â€˜multilevelâ€™ models)</li>
<li>Time series models (autoregressive)</li>
<li>Spatial models (e.g.Â conditional autoregressive)</li>
</ul>
<p>As demonstration is beyond the scope of this document, the main point here is awareness. But see these on <a href="https://m-clark.github.io/mixed-models-with-R/">mixed models</a> and <a href="https://m-clark.github.io/generalized-additive-models/">generalized additive models</a>.</p>
</div>
<div id="other-extensions" class="section level3">
<h3>Other extensions</h3>
<p>There are many types of models that will take one well beyond the standard linear model. In some cases, the focus is multivariate, trying to model many targets at once. Other models will even be domain-specific, tailored to a very narrow type of problem. Whatever the scenario, having a good understanding of the models weâ€™ve been discussing will likely help you navigate these new waters much more easily.</p>
</div>
</div>
<div id="model-exploration-summary" class="section level2">
<h2>Model Exploration Summary</h2>
<p>At this point you should have a good idea of how to get started exploring models with R. Generally what you will explore will be based on theory, or merely curiosity. Specific packages while make certain types of models easy to pull off, without much change to the syntax from the standard <code>lm</code> approach of base R. Almost invariably, you will need to process the data to make it more amenable to analysis and/or more interpretable. After model fitting, summaries and visualizations go a long way toward understanding the part of the world you are exploring.</p>
</div>
<div id="model-exploration-exercises" class="section level2">
<h2>Model Exploration Exercises</h2>
<div id="exercise-1-8" class="section level3">
<h3>Exercise 1</h3>
<p>With the Google app data, use a standard linear model (i.e.Â <span class="func" style="">lm</span>) to predict one of three target variables of your choosing:</p>
<ul>
<li><code>rating</code>: the user ratings of the app</li>
<li><code>avg_sentiment_polarity</code>: the average sentiment score (positive vs.Â negative) for the app</li>
<li><code>avg_sentiment_subjectivity</code>: the average subjectivity score (subjective vs.Â objective) for the app</li>
</ul>
<p>For prediction use the following variables:</p>
<ul>
<li><code>reviews</code>: number of reviews</li>
<li><code>type</code>: free vs.Â paid</li>
<li><code>size_in_MB</code>: size of the app in megabytes</li>
</ul>
<p>I would suggest preprocessing the number of reviews- dividing by 100,000, scaling (standardizing), or logging it (for the latter you can add 1 first to deal with zeros<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a>).</p>
<p>Interpret the results. Visualize the difference in means between free and paid apps. See the <a href="models.html#visualization">emmeans</a> example above.</p>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="models.html#cb449-1"></a><span class="kw">load</span>(<span class="st">&#39;data/google_apps.RData&#39;</span>)</span>
<span id="cb449-2"><a href="models.html#cb449-2"></a></span>
<span id="cb449-3"><a href="models.html#cb449-3"></a>model =<span class="st"> </span><span class="kw">lm</span>(? <span class="op">~</span><span class="st"> </span>reviews <span class="op">+</span><span class="st"> </span>type <span class="op">+</span><span class="st"> </span>size_in_MB, <span class="dt">data =</span> google_apps)</span>
<span id="cb449-4"><a href="models.html#cb449-4"></a></span>
<span id="cb449-5"><a href="models.html#cb449-5"></a><span class="kw">plot</span>(emmeans<span class="op">::</span><span class="kw">emmeans</span>(model, <span class="op">~</span>type))</span></code></pre></div>
</div>
<div id="exercise-2-8" class="section level3">
<h3>Exercise 2</h3>
<p>Rerun the above with interactions of the number of reviews or app size (or both) with type (via <code>a + b + a:b</code> or just <code>a*b</code> for two predictors). Visualize the interaction. Does it look like the effect differs by type?</p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="models.html#cb450-1"></a>model =<span class="st"> </span><span class="kw">lm</span>(? <span class="op">~</span><span class="st"> </span>reviews <span class="op">+</span><span class="st"> </span>type<span class="op">*</span>?, <span class="dt">data =</span> google_apps)</span>
<span id="cb450-2"><a href="models.html#cb450-2"></a></span>
<span id="cb450-3"><a href="models.html#cb450-3"></a><span class="kw">plot</span>(ggeffects<span class="op">::</span><span class="kw">ggpredict</span>(model, <span class="dt">terms =</span> <span class="kw">c</span>(<span class="st">&#39;size_in_MB&#39;</span>, <span class="st">&#39;type&#39;</span>)))</span></code></pre></div>
</div>
<div id="exercise-3-3" class="section level3">
<h3>Exercise 3</h3>
<p>Use the fish data to predict the number of fish caught <code>count</code> by the following predictor variables:</p>
<ul>
<li><code>livebait</code>: whether live bait was used or not</li>
<li><code>child</code>: how many children present</li>
<li><code>persons</code>: total persons on the trip</li>
</ul>
<p>If you wish, you can start with an <code>lm</code>, but as the number of fish caught is a count, it is suitable for using a poisson distribution via <code>glm</code> with <code>family = poisson</code>, so try that if youâ€™re feeling up for it. If you exponentiate the coefficients, they can be interpreted as <a href="https://stats.idre.ucla.edu/stata/output/poisson-regression/">incidence rate ratios</a>.</p>
<div class="sourceCode" id="cb451"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb451-1"><a href="models.html#cb451-1"></a><span class="kw">load</span>(<span class="st">&#39;data/fish.RData&#39;</span>)</span>
<span id="cb451-2"><a href="models.html#cb451-2"></a></span>
<span id="cb451-3"><a href="models.html#cb451-3"></a>model =<span class="st"> </span><span class="kw">glm</span>(?, <span class="dt">data =</span> fish)</span></code></pre></div>
</div>
</div>
<div id="python-model-exploration-notebook" class="section level2">
<h2>Python Model Exploration Notebook</h2>
<p><a href="https://github.com/m-clark/data-processing-and-visualization/blob/master/jupyter_notebooks/models.ipynb">Available on GitHub</a></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="19">
<li id="fn19"><p>I prefer <em>target</em> because it emphasizes where the focus should be- predicting/explaining that variable. It represents the bullseye we are trying to hit. Others, like â€˜responseâ€™ or â€˜outcomeâ€™, imply a specific type of study, and so donâ€™t even make sense in many situations. â€˜Outputâ€™ is too generic, and â€˜dependent variableâ€™, along with its roots in experimental design which is far from the normal data situation, seems to shift focus to the predictors, i.e.Â how the target depends on the covariates, which it often doesnâ€™t, or doesnâ€™t in a practical way. Furthermore, effects of one variable may depend on another, observations are dependent (correlated), etc. For the other side of the equation Iâ€™m more ambivalent, just as long as â€˜independent variableâ€™, which is only applicable in some experimental designs, is not used.<a href="models.html#fnref19" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn20"><p>To be consistent with the many tools that minimize different types of losses, we usually minimize the <em>negative log likelihood</em>, rather than maximize the raw likelihood.<a href="models.html#fnref20" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn21"><p>In this case, a Poisson distribution.<a href="models.html#fnref21" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn22"><p>For example, if the next best guess for a regression coefficient results in only a difference to many decimal places from the previous one, you probably donâ€™t care and can stop your search. Reaching your desired stopping point is known as <em>convergence</em>. In other cases, you may simply set a maximum number of iterations.<a href="models.html#fnref22" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn23"><p>With very large data relative to the number of parameters to estimate, much of the gain for the Bayesian approach is diminished, though some interpretive advantages would remain.<a href="models.html#fnref23" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn24"><p>The World Happiness Report is a survey of the state of global happiness that ranks countries by how happy their citizens perceive themselves to be. Almost all the information here is gleaned from the report and appendices. This regards the report data from 2008-2018 included in the 2019 report.<a href="models.html#fnref24" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn25"><p>No, I have no idea why you canâ€™t use <span class="func" style="">model.response</span> with <span class="func" style="">model.matrix.</span>.<a href="models.html#fnref25" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn26"><p>People tend to get hung up on different models or packages labeling these columns differently, but any GLM and many other similar models are going to provide the same basic information whichever statistical package (R or otherwise) you use, namely: estimated coefficient, the standard error, the test statistic, the p-value associated with that test statistic.<a href="models.html#fnref26" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn27"><p>Note that none of the benefits regard normality. Transforming variables is not done to meet the normality assumption regarding residuals, and would rarely help in that regard.<a href="models.html#fnref27" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn28"><p>The log transformations in the table are approximations that allow an â€˜eyeballableâ€™ interpretation. Typically we use exponentiated coefficients for a more exact interpretation. For example, if y is logged, a one-unit change in x leads to a <span class="math inline">\(100*(e^B-1)\)</span>% change in y. See <a href="https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-do-i-interpret-a-regression-model-when-some-variables-are-log-transformed/">this link</a> for more on interpreting logged variables.<a href="models.html#fnref28" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn29"><p>In econometrics, if both target and predictor variable are logged, the coefficient is referred to as an <a href="https://stats.idre.ucla.edu/sas/faq/how-can-i-interpret-log-transformed-variables-in-terms-of-percent-change-in-linear-regression/">elasticity</a>.<a href="models.html#fnref29" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn30"><p>Some distinguish one-hot from dummy coding in that the former creates a binary variable for all <span class="math inline">\(C\)</span> categorical levels while dummy coding only creates <span class="math inline">\(C-1\)</span> variables, leaving the reference group out. However, the reference group is only left out at model fitting, thereâ€™s no reason not to create all C variables, as it requires no additional effort and you might want to change the reference group.<a href="models.html#fnref30" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn31"><p>For standard regression models, the divisor for calculating the RMSE is the residual degrees of freedom, but more generally it is just N, the sample size, as many modern models may have more parameters than observations.<a href="models.html#fnref31" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn32"><p>Corrections to p-values are generally a poor way to deal with multiple testing. Adding <a href="ml.html#regularization">regularization</a> to shrink the coefficients from the outset is less arbitrary and more conceptually sound, as it makes no reference to an inferential framework that almost no one uses.<a href="models.html#fnref32" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn33"><p>For historical reasons, Poisson is usually denoted with mean <span class="math inline">\(\lambda\)</span>, and with the binomial the probability is often denoted with <span class="math inline">\(\pi\)</span>, but consistency is desired here.<a href="models.html#fnref33" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn34"><p>Before we distinguished models from <a href="models.html#estimation">estimation procedures</a>, and itâ€™s also important to distinguish models from link functions. In some disciplines (mostly one and those trained in its methods), youâ€™ll see some refer to a â€˜logit modelâ€™, for example. However that wouldnâ€™t tell you if the model regards a target that is binary, categorical, ordered categorical, count or has values between zero and one, which cover several types of possible distributions.<a href="models.html#fnref34" class="footnote-back">â†©ï¸Ž</a></p></li>
<li id="fn35"><p>Just for our purposes. If you have zeros, then thatâ€™s usually a sign that a log transform probably isnâ€™t appropriate.<a href="models.html#fnref35" class="footnote-back">â†©ï¸Ž</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="more.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model_criticism.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["twitter", "facebook", "instapaper"],
"google": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"toc_depth": 2,
"scroll_highlight": true
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
